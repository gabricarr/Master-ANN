{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a47cbe9",
   "metadata": {},
   "source": [
    "# News dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af2f165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a76fae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crmgr\\AppData\\Local\\Temp\\ipykernel_9372\\1676302587.py:3: DtypeWarning: Columns (3,5,6,7,8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  news_df = pd.read_csv(path)\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/news/nasdaq_external_data.csv\"\n",
    "\n",
    "news_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7330262",
   "metadata": {},
   "source": [
    "# News dataset inpection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e9b0135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Stock_symbol</th>\n",
       "      <th>Url</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Author</th>\n",
       "      <th>Article</th>\n",
       "      <th>Lsa_summary</th>\n",
       "      <th>Luhn_summary</th>\n",
       "      <th>Textrank_summary</th>\n",
       "      <th>Lexrank_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-12-16 23:00:00 UTC</td>\n",
       "      <td>Interesting A Put And Call Options For August ...</td>\n",
       "      <td>A</td>\n",
       "      <td>https://www.nasdaq.com/articles/interesting-a-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investors in Agilent Technologies, Inc. (Symbo...</td>\n",
       "      <td>Because the $125.00 strike represents an appro...</td>\n",
       "      <td>The current analytical data (including greeks ...</td>\n",
       "      <td>Below is a chart showing the trailing twelve m...</td>\n",
       "      <td>At Stock Options Channel, our YieldBoost formu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2023-12-12 00:00:00 UTC</td>\n",
       "      <td>Wolfe Research Initiates Coverage of Agilent T...</td>\n",
       "      <td>A</td>\n",
       "      <td>https://www.nasdaq.com/articles/wolfe-research...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fintel reports that on December 13, 2023, Wolf...</td>\n",
       "      <td>Fintel reports that on December 13, 2023, Wolf...</td>\n",
       "      <td>T. Rowe Price Investment Management holds 10,1...</td>\n",
       "      <td>Agilent Technologies Declares $0.24 Dividend O...</td>\n",
       "      <td>The projected annual revenue for Agilent Techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2023-12-12 00:00:00 UTC</td>\n",
       "      <td>Agilent Technologies Reaches Analyst Target Price</td>\n",
       "      <td>A</td>\n",
       "      <td>https://www.nasdaq.com/articles/agilent-techno...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>When a stock reaches the target an analyst has...</td>\n",
       "      <td>When a stock reaches the target an analyst has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2023-12-07 00:00:00 UTC</td>\n",
       "      <td>Agilent (A) Enhances BioTek Cytation C10 With ...</td>\n",
       "      <td>A</td>\n",
       "      <td>https://www.nasdaq.com/articles/agilent-a-enha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agilent Technologies A is enhancing its BioTek...</td>\n",
       "      <td>Per a Grand View Research report, the global m...</td>\n",
       "      <td>Notably, Agilent enhanced the BioTek Cytation ...</td>\n",
       "      <td>Agilent Technologies, Inc. Price and Consensus...</td>\n",
       "      <td>Notably, Agilent enhanced the BioTek Cytation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2023-12-07 00:00:00 UTC</td>\n",
       "      <td>Pre-Market Most Active for Dec 7, 2023 : SQQQ,...</td>\n",
       "      <td>A</td>\n",
       "      <td>https://www.nasdaq.com/articles/pre-market-mos...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The NASDAQ 100 Pre-Market Indicator is up 70.2...</td>\n",
       "      <td>ProShares UltraPro Short QQQ (SQQQ) is -0.15 a...</td>\n",
       "      <td>As reported by Zacks, the current mean recomme...</td>\n",
       "      <td>The total Pre-Market volume is currently 39,23...</td>\n",
       "      <td>The NASDAQ 100 Pre-Market Indicator is up 70.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     Date  \\\n",
       "0         0.0  2023-12-16 23:00:00 UTC   \n",
       "1         1.0  2023-12-12 00:00:00 UTC   \n",
       "2         2.0  2023-12-12 00:00:00 UTC   \n",
       "3         3.0  2023-12-07 00:00:00 UTC   \n",
       "4         4.0  2023-12-07 00:00:00 UTC   \n",
       "\n",
       "                                       Article_title Stock_symbol  \\\n",
       "0  Interesting A Put And Call Options For August ...            A   \n",
       "1  Wolfe Research Initiates Coverage of Agilent T...            A   \n",
       "2  Agilent Technologies Reaches Analyst Target Price            A   \n",
       "3  Agilent (A) Enhances BioTek Cytation C10 With ...            A   \n",
       "4  Pre-Market Most Active for Dec 7, 2023 : SQQQ,...            A   \n",
       "\n",
       "                                                 Url Publisher Author  \\\n",
       "0  https://www.nasdaq.com/articles/interesting-a-...       NaN    NaN   \n",
       "1  https://www.nasdaq.com/articles/wolfe-research...       NaN    NaN   \n",
       "2  https://www.nasdaq.com/articles/agilent-techno...       NaN    NaN   \n",
       "3  https://www.nasdaq.com/articles/agilent-a-enha...       NaN    NaN   \n",
       "4  https://www.nasdaq.com/articles/pre-market-mos...       NaN    NaN   \n",
       "\n",
       "                                             Article  \\\n",
       "0  Investors in Agilent Technologies, Inc. (Symbo...   \n",
       "1  Fintel reports that on December 13, 2023, Wolf...   \n",
       "2  In recent trading, shares of Agilent Technolog...   \n",
       "3  Agilent Technologies A is enhancing its BioTek...   \n",
       "4  The NASDAQ 100 Pre-Market Indicator is up 70.2...   \n",
       "\n",
       "                                         Lsa_summary  \\\n",
       "0  Because the $125.00 strike represents an appro...   \n",
       "1  Fintel reports that on December 13, 2023, Wolf...   \n",
       "2  In recent trading, shares of Agilent Technolog...   \n",
       "3  Per a Grand View Research report, the global m...   \n",
       "4  ProShares UltraPro Short QQQ (SQQQ) is -0.15 a...   \n",
       "\n",
       "                                        Luhn_summary  \\\n",
       "0  The current analytical data (including greeks ...   \n",
       "1  T. Rowe Price Investment Management holds 10,1...   \n",
       "2  In recent trading, shares of Agilent Technolog...   \n",
       "3  Notably, Agilent enhanced the BioTek Cytation ...   \n",
       "4  As reported by Zacks, the current mean recomme...   \n",
       "\n",
       "                                    Textrank_summary  \\\n",
       "0  Below is a chart showing the trailing twelve m...   \n",
       "1  Agilent Technologies Declares $0.24 Dividend O...   \n",
       "2  When a stock reaches the target an analyst has...   \n",
       "3  Agilent Technologies, Inc. Price and Consensus...   \n",
       "4  The total Pre-Market volume is currently 39,23...   \n",
       "\n",
       "                                     Lexrank_summary  \n",
       "0  At Stock Options Channel, our YieldBoost formu...  \n",
       "1  The projected annual revenue for Agilent Techn...  \n",
       "2  When a stock reaches the target an analyst has...  \n",
       "3  Notably, Agilent enhanced the BioTek Cytation ...  \n",
       "4  The NASDAQ 100 Pre-Market Indicator is up 70.2...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f18b278f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15549299\n",
      "Index(['Unnamed: 0', 'Date', 'Article_title', 'Stock_symbol', 'Url',\n",
      "       'Publisher', 'Author', 'Article', 'Lsa_summary', 'Luhn_summary',\n",
      "       'Textrank_summary', 'Lexrank_summary'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(len(news_df))\n",
    "print(news_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15c7d723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Unnamed: 0: 2491785\n",
      "[0.000000e+00 1.000000e+00 2.000000e+00 ... 2.491783e+06 2.491784e+06\n",
      "          nan]\n",
      "\n",
      "Unique values in Date: 2796596\n",
      "['2023-12-16 23:00:00 UTC' '2023-12-12 00:00:00 UTC'\n",
      " '2023-12-07 00:00:00 UTC' ... '2013-11-10 02:40:00 UTC'\n",
      " '2013-11-10 02:39:00 UTC' '2013-11-10 00:46:00 UTC']\n",
      "\n",
      "Unique values in Article_title: 10452636\n",
      "['Interesting A Put And Call Options For August 2024'\n",
      " 'Wolfe Research Initiates Coverage of Agilent Technologies (A) with Outperform Recommendation'\n",
      " 'Agilent Technologies Reaches Analyst Target Price' ...\n",
      " 'Apple Said to Add Foxconn’s Chimei as Supplier of Parts for IPad'\n",
      " 'CEZ, Bank Pekao Shares May Move: Central European Stock Preview'\n",
      " 'Popolare di Milano May Join Intesa, Paschi in Selling Shares This Year']\n",
      "\n",
      "Unique values in Stock_symbol: 8552\n",
      "['A' 'AA' 'AAAU' ... 'XVZ' 'YGRO' 'YPRO']\n",
      "\n",
      "Unique values in Url: 12745848\n",
      "['https://www.nasdaq.com/articles/interesting-a-put-and-call-options-for-august-2024'\n",
      " 'https://www.nasdaq.com/articles/wolfe-research-initiates-coverage-of-agilent-technologies-a-with-outperform-recommendation'\n",
      " 'https://www.nasdaq.com/articles/agilent-technologies-reaches-analyst-target-price-0'\n",
      " ...\n",
      " 'http://www.bloomberg.com/news/2011-04-19/cez-bank-pekao-shares-may-move-central-european-stock-preview.html\\n'\n",
      " 'http://www.bloomberg.com/news/2011-04-19/popolare-di-milano-may-join-intesa-paschi-in-selling-shares-this-year.html\\n'\n",
      " 'http://www.bloomberg.com/news/2011-04-19/gold-may-top-1-500-extending-rally-to-record-as-u-s-credit-outlook-cut.html\\n']\n",
      "\n",
      "Unique values in Publisher: 1142\n",
      "[nan 'Benzinga Insights' 'Lisa Levin' ... 'msnmoney' 'Marketfy'\n",
      " 'Born2Invest']\n",
      "\n",
      "Unique values in Author: 37000\n",
      "[nan 'Библиотека' 'Россия' ...\n",
      " 'B y   M a r i a n n e   S t i g s e t   a n d   O s h r a t   C a r m i e l'\n",
      " 'B y   D a r r e l l   P r e s t o n   a n d   J o h n   M c C o r m i c k'\n",
      " 'B y   M a r i a   K o l e s n i k o v a   a n d   K y o u n g w h a   K i m']\n",
      "\n",
      "Unique values in Article: 2430438\n",
      "['Investors in Agilent Technologies, Inc. (Symbol: A) saw new options begin trading this week, for the August 2024 expiration. One of the key inputs that goes into the price an option buyer is willing to pay, is the time value, so with 241 days until expiration the newly trading contracts represent a possible opportunity for sellers of puts or calls to achieve a higher premium than would be available for the contracts with a closer expiration. At Stock Options Channel, our YieldBoost formula has looked up and down the A options chain for the new August 2024 contracts and identified one put and one call contract of particular interest.\\nThe put contract at the $125.00 strike price has a current bid of $4.50. If an investor was to sell-to-open that put contract, they are committing to purchase the stock at $125.00, but will also collect the premium, putting the cost basis of the shares at $120.50 (before broker commissions). To an investor already interested in purchasing shares of A, that could represent an attractive alternative to paying $138.99/share today.\\nBecause the $125.00 strike represents an approximate 10% discount to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the put contract would expire worthless. The current analytical data (including greeks and implied greeks) suggest the current odds of that happening are 77%. Stock Options Channel will track those odds over time to see how they change, publishing a chart of those numbers on our website under the contract detail page for this contract. Should the contract expire worthless, the premium would represent a 3.60% return on the cash commitment, or 5.45% annualized — at Stock Options Channel we call this the YieldBoost.\\nBelow is a chart showing the trailing twelve month trading history for Agilent Technologies, Inc., and highlighting in green where the $125.00 strike is located relative to that history:\\nTurning to the calls side of the option chain, the call contract at the $150.00 strike price has a current bid of $8.10. If an investor was to purchase shares of A stock at the current price level of $138.99/share, and then sell-to-open that call contract as a \"covered call,\" they are committing to sell the stock at $150.00. Considering the call seller will also collect the premium, that would drive a total return (excluding dividends, if any) of 13.75% if the stock gets called away at the August 2024 expiration (before broker commissions). Of course, a lot of upside could potentially be left on the table if A shares really soar, which is why looking at the trailing twelve month trading history for Agilent Technologies, Inc., as well as studying the business fundamentals becomes important. Below is a chart showing A\\'s trailing twelve month trading history, with the $150.00 strike highlighted in red:\\nConsidering the fact that the $150.00 strike represents an approximate 8% premium to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the covered call contract would expire worthless, in which case the investor would keep both their shares of stock and the premium collected. The current analytical data (including greeks and implied greeks) suggest the current odds of that happening are 53%. On our website under the contract detail page for this contract, Stock Options Channel will track those odds over time to see how they change and publish a chart of those numbers (the trading history of the option contract will also be charted). Should the covered call contract expire worthless, the premium would represent a 5.83% boost of extra return to the investor, or 8.83% annualized, which we refer to as the YieldBoost.\\nThe implied volatility in the put contract example is 32%, while the implied volatility in the call contract example is 29%.\\nMeanwhile, we calculate the actual trailing twelve month volatility (considering the last 251 trading day closing values as well as today\\'s price of $138.99) to be 27%. For more put and call options contract ideas worth looking at, visit StockOptionsChannel.com.\\nTop YieldBoost Calls of Stocks Analysts Like »\\nAlso see:\\n\\x95 Canadian Stocks Crossing Below Their 200 Day Moving Avg\\n\\x95 Funds Holding SNUG\\n\\x95 CCE Insider Buying\\nThe views and opinions expressed herein are the views and opinions of the author and do not necessarily reflect those of Nasdaq, Inc.'\n",
      " \"Fintel reports that on December 13, 2023, Wolfe Research initiated coverage of Agilent Technologies (NYSE:A) with a Outperform recommendation.\\nAnalyst Price Forecast Suggests 1.04% Downside\\nAs of November 27, 2023, the average one-year price target for Agilent Technologies is 132.34. The forecasts range from a low of 101.00 to a high of $157.50. The average price target represents a decrease of 1.04% from its latest reported closing price of 133.74.\\nSee our leaderboard of companies with the largest price target upside.\\nThe projected annual revenue for Agilent Technologies is 7,130MM, an increase of 4.35%. The projected annual non-GAAP EPS is 5.77.\\nAgilent Technologies Declares $0.24 Dividend\\nOn November 15, 2023 the company declared a regular quarterly dividend of $0.24 per share ($0.94 annualized). Shareholders of record as of January 2, 2024 will receive the payment on January 24, 2024. Previously, the company paid $0.22 per share.\\nAt the current share price of $133.74 / share, the stock's dividend yield is 0.71%.\\nLooking back five years and taking a sample every week, the average dividend yield has been 0.72%, the lowest has been 0.44%, and the highest has been 1.14%. The standard deviation of yields is 0.14 (n=235).\\nThe current dividend yield is 0.12 standard deviations below the historical average.\\nAdditionally, the company's dividend payout ratio is 0.22. The payout ratio tells us how much of a company's income is paid out in dividends. A payout ratio of one (1.0) means 100% of the company's income is paid in a dividend. A payout ratio greater than one means the company is dipping into savings in order to maintain its dividend - not a healthy situation. Companies with few growth prospects are expected to pay out most of their income in dividends, which typically means a payout ratio between 0.5 and 1.0. Companies with good growth prospects are expected to retain some earnings in order to invest in those growth prospects, which translates to a payout ratio of zero to 0.5.\\nThe company's 3-Year dividend growth rate is 0.22%, demonstrating that it has increased its dividend over time.\\nWhat is the Fund Sentiment?\\nThere are 1945 funds or institutions reporting positions in Agilent Technologies. This is an increase of 30 owner(s) or 1.57% in the last quarter. Average portfolio weight of all funds dedicated to A is 0.31%, a decrease of 2.75%. Total shares owned by institutions increased in the last three months by 1.25% to 300,740K shares.\\nThe put/call ratio of A is 1.01, indicating a bearish outlook.\\nWhat are Other Shareholders Doing?\\nMassachusetts Financial Services holds 11,076K shares representing 3.79% ownership of the company. In it's prior filing, the firm reported owning 11,037K shares, representing an increase of 0.35%. The firm increased its portfolio allocation in A by 546.51% over the last quarter.\\nWellington Management Group Llp holds 10,256K shares representing 3.51% ownership of the company. In it's prior filing, the firm reported owning 8,736K shares, representing an increase of 14.81%. The firm increased its portfolio allocation in A by 15.48% over the last quarter.\\nT. Rowe Price Investment Management holds 10,122K shares representing 3.47% ownership of the company. In it's prior filing, the firm reported owning 9,968K shares, representing an increase of 1.53%. The firm decreased its portfolio allocation in A by 2.00% over the last quarter.\\nVTSMX - Vanguard Total Stock Market Index Fund Investor Shares holds 9,113K shares representing 3.12% ownership of the company. In it's prior filing, the firm reported owning 9,177K shares, representing a decrease of 0.70%. The firm decreased its portfolio allocation in A by 4.15% over the last quarter.\\nPrice T Rowe Associates holds 7,386K shares representing 2.53% ownership of the company. In it's prior filing, the firm reported owning 8,054K shares, representing a decrease of 9.05%. The firm decreased its portfolio allocation in A by 10.32% over the last quarter.\\nAgilent Technologies Background Information\\n(This description is provided by the company.)\\nAgilent Technologies Inc. is a global leader in life sciences, diagnostics, and applied chemical markets, delivering insight and innovation toward improving the quality of life. Agilent instruments, software, services, solutions, and people provide trusted answers to customers' most challenging questions. The company generated revenue of $5.34 billion in fiscal year 2020 and employs 16,400 people worldwide.\\nFintel is one of the most comprehensive investing research platforms available to individual investors, traders, financial advisors, and small hedge funds.\\nOur data covers the world, and includes fundamentals, analyst reports, ownership data and fund sentiment, options sentiment, insider trading, options flow, unusual options trades, and much more. Additionally, our exclusive stock picks are powered by advanced, backtested quantitative models for improved profits.\\nClick to Learn More\\nThis story originally appeared on Fintel.\\nThe views and opinions expressed herein are the views and opinions of the author and do not necessarily reflect those of Nasdaq, Inc.\"\n",
      " 'In recent trading, shares of Agilent Technologies, Inc. (Symbol: A) have crossed above the average analyst 12-month target price of $132.36, changing hands for $133.74/share. When a stock reaches the target an analyst has set, the analyst logically has two ways to react: downgrade on valuation, or, re-adjust their target price to a higher level. Analyst reaction may also depend on the fundamental business developments that may be responsible for driving the stock price higher — if things are looking up for the company, perhaps it is time for that target price to be raised.\\nThere are 14 different analyst targets within the Zacks coverage universe contributing to that average for Agilent Technologies, Inc., but the average is just that — a mathematical average. There are analysts with lower targets than the average, including one looking for a price of $100.00. And then on the other side of the spectrum one analyst has a target as high as $146.00. The standard deviation is $12.779.\\nBut the whole reason to look at the average A price target in the first place is to tap into a \"wisdom of crowds\" effort, putting together the contributions of all the individual minds who contributed to the ultimate number, as opposed to what just one particular expert believes. And so with A crossing above that average target price of $132.36/share, investors in A have been given a good signal to spend fresh time assessing the company and deciding for themselves: is $132.36 just one stop on the way to an even higher target, or has the valuation gotten stretched to the point where it is time to think about taking some chips off the table? Below is a table showing the current thinking of the analysts that cover Agilent Technologies, Inc.:\\nRECENT A ANALYST RATINGS BREAKDOWN\\n» Current 1 Month Ago 2 Month Ago 3 Month Ago\\nStrong buy ratings: 7 9 9 9\\nBuy ratings: 0 0 0 0\\nHold ratings: 7 5 5 4\\nSell ratings: 0 0 0 0\\nStrong sell ratings: 1 1 1 1\\nAverage rating: 2.2 1.93 1.93 1.86\\nThe average rating presented in the last row of the above table above is from 1 to 5 where 1 is Strong Buy and 5 is Strong Sell. This article used data provided by Zacks Investment Research via Quandl.com. Get the latest Zacks research report on A — FREE.\\nThe Top 25 Broker Analyst Picks of the S&P 500 »\\nAlso see:\\n\\x95 PXMD Insider Buying\\n\\x95 ETM Insider Buying\\n\\x95 Funds Holding FXG\\nThe views and opinions expressed herein are the views and opinions of the author and do not necessarily reflect those of Nasdaq, Inc.'\n",
      " ...\n",
      " 'The following is a list of\\ncompanies whose shares may have unusual price changes in central\\nEuropean markets. Stock symbols are in parentheses after company\\nnames. Share prices are from the last close.  Poland ’s WIG20 Index fell 1.5 percent, the Czech PX Index\\nlost 1.4 percent and  Hungary ’s BUX Index slumped 3.8 percent.  CEZ AS (CEZ)  : The Czech Republic’s largest utility said\\nunit 4 at its Dukovany nuclear plant is now at 75 percent of\\noutput while unit 2 has reached 90 percent of output. Unit 4 was\\nunexpectedly shut down on April 14 and unit 2 is returning to\\nfull power after a planned service outage. CEZ shares declined\\n1.1 percent to 871 koruna.  Bank Pekao SA (PEO)  : Shareholders of Poland’s second-\\nlargest bank are scheduled to vote on a dividend payout from\\n2010 profit. Pekao shares declined 1.5 percent to 173.3 zloty.  To contact the reporters on this story:\\nPawel Kozlowski in Warsaw \\n pkozlowski@bloomberg.net   To contact the editor responsible for this story:\\nGavin Serkin at \\n gserkin@bloomberg.net'\n",
      " 'Banca Popolare di Milano Scrl,\\n Italy ’s oldest cooperative bank, may join Intesa Sanpaolo SpA\\nand Banca Monte dei Paschi di Siena SpA in selling new shares\\nthis year to boost capital.  The board of the Milan-based lender will meet today to\\nconsider a rights offer after the  Bank of Italy  sent a letter\\nasking it to reinforce its capital, two people familiar with the\\nsituation said April 14. Popolare Milano, which has to reimburse\\na 500 million-euro ($725 million) government bond by 2013,\\nrejected two weeks ago a proposal to sell new shares to boost\\nits  capital ratios , according to the people.  Bank of Italy Governor  Mario Draghi  in February urged the\\ncountry’s lenders to use profits to strengthen their reserves\\nand said he expects banks to raise money ahead of this year’s\\nstress test, which should be completed by June.  Popolare di Milano would be the fifth Italian lender to\\nannounce a capital increase. Banco Popolare SC concluded a 2\\nbillion-euro share sale in February, while Unione di Banche\\nItaliane SCPA in March asked investors to buy 1 billion euros of\\nnew shares. Intesa and Monte Paschi, the country’s No. 2 and No.\\n3 banks, have approved rights offer of 5 billion euros and 2\\nbillion euros respectively.  Basel Rules  “Rights issues are unavoidable for Italian banks to have\\nan adequate capital base to face new Basel rules,” said Angelo Manca, a portfolio manager at Ockham Capital Partners in  London .\\n“Recent decisions taken by banks traditionally seen as solid,\\nsuch as UBI and Intesa, confirm that.”  The Group of 20 nations last year endorsed rules proposed\\nby the  Basel Committee on Banking Supervision  that would triple\\nthe highest-quality capital that lenders need to hold. The\\ncommittee may also apply tougher rules to European banks\\nconsidered “systemically important financial institutions.”  UniCredit SpA, which raised 7 billion euros in the last\\nthree years through two capital increases, is the only bank\\namong Italy’s top five lenders that hasn’t asked for money from\\nits investors this year. Chief Executive Officer  Federico Ghizzoni  said April 2 that the capital of Italy’s biggest bank\\nis sufficient and its ratios already meet the Basel III\\nrequirements.  To contact the reporter on this story:\\nSonia Sirletti in Milan at \\n ssirletti@bloomberg.net   To contact the editor responsible for this story:\\nFrank Connelly at   fconnelly@bloomberg.net'\n",
      " 'Gold extended gains to a record in\\n New York  as a drop in the dollar buoyed demand for the metal as\\nan alternative investment.  Futures surged yesterday after  Standard & Poor’s  revised\\nits U.S. credit outlook to negative. Gold has jumped 5.3 percent\\nthis year as the dollar dropped 4.8 percent against a basket of\\nsix other currencies including the euro and British pound.  Gold prices may keep rising for “some years into the\\nfuture,”  Blackrock Inc. (BLK)  fund manager  Evy Hambro  said in an\\ninterview with  Mark Barton  on Bloomberg TV’s “On the Move.”  Gold for June delivery rose $1.60, or 0.1 percent, to\\n$1,494.60 an ounce by 8:20 a.m. in New York after earlier today\\nclimbing to $1,498.90. Immediate-delivery gold was little\\nchanged at $1,493.93 an ounce in  London .  The 14-day relative strength index of gold futures rose to\\n70.135, above the level of 70 that some analysts who study\\ncharts view as a sign that prices are poised to drop.  “$1,500 is definitely a psychological level,” said Mark\\nO’Byrne, executive director of brokerage GoldCore Ltd. in\\nDublin. “Any correction is likely to be short and shallow,\\ngiven the very strong fundamentals.”  At current prices, gold is still $900 below the inflation-\\nadjusted level, GoldCore’s O’Byrne said, adding that gold may\\nreach as much as $2,400 in the coming years.  ‘Debt Issue’  “The focus has moved to the U.S. sovereign debt issue,”\\nO’Byrne said. “There are very significant risks in the world,\\nthat’s why people are diversifying into gold. Before, the  U.S.\\ngovernment debt  was meant to be risk free. Now that is in\\nquestion.”  Gold has gained in the last 10 years on increased\\ninvestment demand for commodities and on concern that currencies\\nmay be debased as central banks stimulate their economies.\\nUnrest in the Middle East, sovereign-debt turmoil in  Europe  and\\nJapan’s nuclear crisis have bolstered sales, propelling bullion\\n32 percent higher in the past year.  Additional support for gold came from quickening inflation\\nthat has prompted policy makers across the globe to raise\\n interest rates . Consumer prices in  China  rose at their quickest\\npace since 2008 in March, exceeding the government’s 2011 target\\nfor a third month.  Inflation ‘Impetus’  Inflation in the 17-nation euro region quickened to 2.7\\npercent from 2.4 percent in February, the European Union’s\\nstatistics office said last week. U.S. wholesale costs rose 5.8\\npercent in March compared with a year earlier, and the\\ngovernment said that the cost of living rose for a ninth month.  “Growing fears of rising inflation and a weak dollar\\ncontinue to benefit gold and silver,” Marc Ground, an analyst\\nat  Standard Bank , wrote in a note. “Inflation-hedge buying is\\nproviding the main impetus.”  Gold held in exchange-traded products rose 0.36 metric tons\\nto 2,070.32 tons yesterday, the highest level since Jan. 24,\\ndata compiled by Bloomberg from 10 providers show.  Silver for May delivery gained 0.7 percent to $43.275 an\\nounce. Palladium for June delivery was up 0.7 percent at $744.35\\nan ounce and platinum for July delivery rose 0.3 percent to\\n$1,788.70 an ounce. With assistance from Chanyaporn Chanjaroen in Singapore.\\nEditors: John Deane, Dan Weeks  To contact the reporters on this story:\\nKyoungwha Kim in Singapore at \\n kkim19@bloomberg.net ;\\nMaria Kolesnikova in Moscow at \\n mkolesnikova@bloomberg.net   To contact the editor responsible for this story:\\nClaudia Carpenter at \\n ccarpenter2@bloomberg.net']\n",
      "\n",
      "Unique values in Lsa_summary: 1716271\n",
      "[\"Because the $125.00 strike represents an approximate 10% discount to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the put contract would expire worthless. Of course, a lot of upside could potentially be left on the table if A shares really soar, which is why looking at the trailing twelve month trading history for Agilent Technologies, Inc., as well as studying the business fundamentals becomes important. Below is a chart showing A's trailing twelve month trading history, with the $150.00 strike highlighted in red: Considering the fact that the $150.00 strike represents an approximate 8% premium to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the covered call contract would expire worthless, in which case the investor would keep both their shares of stock and the premium collected.\"\n",
      " \"Fintel reports that on December 13, 2023, Wolfe Research initiated coverage of Agilent Technologies (NYSE:A) with a Outperform recommendation. Agilent instruments, software, services, solutions, and people provide trusted answers to customers' most challenging questions. Fintel is one of the most comprehensive investing research platforms available to individual investors, traders, financial advisors, and small hedge funds.\"\n",
      " 'In recent trading, shares of Agilent Technologies, Inc. (Symbol: A) have crossed above the average analyst 12-month target price of $132.36, changing hands for $133.74/share. And so with A crossing above that average target price of $132.36/share, investors in A have been given a good signal to spend fresh time assessing the company and deciding for themselves: is $132.36 just one stop on the way to an even higher target, or has the valuation gotten stretched to the point where it is time to think about taking some chips off the table? The Top 25 Broker Analyst Picks of the S&P 500 » Also see: \\x95 PXMD Insider Buying \\x95 ETM Insider Buying \\x95 Funds Holding FXG The views and opinions expressed herein are the views and opinions of the author and do not necessarily reflect those of Nasdaq, Inc.'\n",
      " ...\n",
      " 'Q2 2012 Financial Results: Strong Revenue and Gross Margin But Op Expenses Remain High… Brian Marckx, CFA Zynex Inc (ZYXI) reported financial results for second quarter ending June 30, 2012 on August 7th. Please visit scr.zacks.com to access a free copy of the ZYXI research report. ZYNEX INC (ZYXI): Free Stock Analysis Report To read this article on Zacks.com click here.'\n",
      " '35% Revenue Growth in Q1 Brian Marckx, CFA Revenue Zynex Inc. (ZYXI) reported financial results for the first quarter ending March 31, 2012 on May 8th. ZYNEX INC (ZYXI): Free Stock Analysis Report To read this article on Zacks.com click here. Management noted on the call that they expect cash on the balance sheet and borrowing availability under this loan to be sufficient to fund operations until at least the end of the current year.'\n",
      " \"To view a free copy of our most recent research report on ZYXIor subscribe to our daily morning email alert, visit Brian Marckx's coverage page at http://scr.zacks.com/ . Q4 2011 Financial Results: Largely In-Line with Our Numbers... Brian Marckx, CFA Revenue Zynex Inc. (ZYXI) reported financial results for the fourth quarter ending December 31, 2011 on March 15th. ZYXI did a good job of doing exactly that throughout 2011, with SG&A as % of sales falling from 71.9% in 2010 to 69.3% in 2011.\"]\n",
      "\n",
      "Unique values in Luhn_summary: 1704492\n",
      "['The current analytical data (including greeks and implied greeks) suggest the current odds of that happening are 77%. Below is a chart showing the trailing twelve month trading history for Agilent Technologies, Inc., and highlighting in green where the $125.00 strike is located relative to that history: Turning to the calls side of the option chain, the call contract at the $150.00 strike price has a current bid of $8.10. The current analytical data (including greeks and implied greeks) suggest the current odds of that happening are 53%.'\n",
      " 'T. Rowe Price Investment Management holds 10,122K shares representing 3.47% ownership of the company. VTSMX - Vanguard Total Stock Market Index Fund Investor Shares holds 9,113K shares representing 3.12% ownership of the company. Our data covers the world, and includes fundamentals, analyst reports, ownership data and fund sentiment, options sentiment, insider trading, options flow, unusual options trades, and much more.'\n",
      " 'In recent trading, shares of Agilent Technologies, Inc. (Symbol: A) have crossed above the average analyst 12-month target price of $132.36, changing hands for $133.74/share. » Current 1 Month Ago 2 Month Ago 3 Month Ago Strong buy ratings: 7 9 9 9 Buy ratings: 0 0 0 0 Hold ratings: 7 5 5 4 Sell ratings: 0 0 0 0 Strong sell ratings: 1 1 1 1 Average rating: 2.2 1.93 1.93 1.86 The average rating presented in the last row of the above table above is from 1 to 5 where 1 is Strong Buy and 5 is Strong Sell. The Top 25 Broker Analyst Picks of the S&P 500 » Also see: \\x95 PXMD Insider Buying \\x95 ETM Insider Buying \\x95 Funds Holding FXG The views and opinions expressed herein are the views and opinions of the author and do not necessarily reflect those of Nasdaq, Inc.'\n",
      " ...\n",
      " 'Q2 2012 Financial Results: Strong Revenue and Gross Margin But Op Expenses Remain High… Brian Marckx, CFA Zynex Inc (ZYXI) reported financial results for second quarter ending June 30, 2012 on August 7th. Please visit scr.zacks.com to access a free copy of the ZYXI research report. ZYNEX INC (ZYXI): Free Stock Analysis Report To read this article on Zacks.com click here.'\n",
      " '35% Revenue Growth in Q1 Brian Marckx, CFA Revenue Zynex Inc. (ZYXI) reported financial results for the first quarter ending March 31, 2012 on May 8th. ZYNEX INC (ZYXI): Free Stock Analysis Report To read this article on Zacks.com click here. We continue to model gross margin to remain near, to slightly below the level for the full-year 2011 (78.4%) going forward based on our assumption that lower margin product sales grow faster than the higher margin rentals business.'\n",
      " \"Q4 2011 Financial Results: Largely In-Line with Our Numbers... Brian Marckx, CFA Revenue Zynex Inc. (ZYXI) reported financial results for the fourth quarter ending December 31, 2011 on March 15th. ZYXI did a good job of doing exactly that throughout 2011, with SG&A as % of sales falling from 71.9% in 2010 to 69.3% in 2011. To view a free copy of our most recent research report on ZYXIor subscribe to our daily morning email alert, visit Brian Marckx's coverage page at http://scr.zacks.com/ .\"]\n",
      "\n",
      "Unique values in Textrank_summary: 1700712\n",
      "[\"Below is a chart showing the trailing twelve month trading history for Agilent Technologies, Inc., and highlighting in green where the $125.00 strike is located relative to that history: Turning to the calls side of the option chain, the call contract at the $150.00 strike price has a current bid of $8.10. Below is a chart showing A's trailing twelve month trading history, with the $150.00 strike highlighted in red: Considering the fact that the $150.00 strike represents an approximate 8% premium to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the covered call contract would expire worthless, in which case the investor would keep both their shares of stock and the premium collected. On our website under the contract detail page for this contract, Stock Options Channel will track those odds over time to see how they change and publish a chart of those numbers (the trading history of the option contract will also be charted).\"\n",
      " \"Agilent Technologies Declares $0.24 Dividend On November 15, 2023 the company declared a regular quarterly dividend of $0.24 per share ($0.94 annualized). In it's prior filing, the firm reported owning 11,037K shares, representing an increase of 0.35%. VTSMX - Vanguard Total Stock Market Index Fund Investor Shares holds 9,113K shares representing 3.12% ownership of the company.\"\n",
      " 'When a stock reaches the target an analyst has set, the analyst logically has two ways to react: downgrade on valuation, or, re-adjust their target price to a higher level. There are 14 different analyst targets within the Zacks coverage universe contributing to that average for Agilent Technologies, Inc., but the average is just that — a mathematical average. » Current 1 Month Ago 2 Month Ago 3 Month Ago Strong buy ratings: 7 9 9 9 Buy ratings: 0 0 0 0 Hold ratings: 7 5 5 4 Sell ratings: 0 0 0 0 Strong sell ratings: 1 1 1 1 Average rating: 2.2 1.93 1.93 1.86 The average rating presented in the last row of the above table above is from 1 to 5 where 1 is Strong Buy and 5 is Strong Sell.'\n",
      " ...\n",
      " 'Q2 2012 Financial Results: Strong Revenue and Gross Margin But Op Expenses Remain High… Brian Marckx, CFA Zynex Inc (ZYXI) reported financial results for second quarter ending June 30, 2012 on August 7th. Please visit scr.zacks.com to access a free copy of the ZYXI research report. ZYNEX INC (ZYXI): Free Stock Analysis Report To read this article on Zacks.com click here.'\n",
      " '35% Revenue Growth in Q1 Brian Marckx, CFA Revenue Zynex Inc. (ZYXI) reported financial results for the first quarter ending March 31, 2012 on May 8th. ZYNEX INC (ZYXI): Free Stock Analysis Report To read this article on Zacks.com click here. We continue to model strong growth in products sales coming from further expansion in the sales force, incremental contribution from the recent NeuroDyne acquisition, the recurring revenue stream from consumables (over an ever larger installed base), and introduction of new products in the Zynex Medical (i.e. - electrotherapy) business.'\n",
      " \"Q4 2011 Financial Results: Largely In-Line with Our Numbers... Brian Marckx, CFA Revenue Zynex Inc. (ZYXI) reported financial results for the fourth quarter ending December 31, 2011 on March 15th. ZYXI did a good job of doing exactly that throughout 2011, with SG&A as % of sales falling from 71.9% in 2010 to 69.3% in 2011. To view a free copy of our most recent research report on ZYXIor subscribe to our daily morning email alert, visit Brian Marckx's coverage page at http://scr.zacks.com/ .\"]\n",
      "\n",
      "Unique values in Lexrank_summary: 1722657\n",
      "[\"At Stock Options Channel, our YieldBoost formula has looked up and down the A options chain for the new August 2024 contracts and identified one put and one call contract of particular interest. Should the contract expire worthless, the premium would represent a 3.60% return on the cash commitment, or 5.45% annualized — at Stock Options Channel we call this the YieldBoost. Below is a chart showing A's trailing twelve month trading history, with the $150.00 strike highlighted in red: Considering the fact that the $150.00 strike represents an approximate 8% premium to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the covered call contract would expire worthless, in which case the investor would keep both their shares of stock and the premium collected.\"\n",
      " \"The projected annual revenue for Agilent Technologies is 7,130MM, an increase of 4.35%. At the current share price of $133.74 / share, the stock's dividend yield is 0.71%. Additionally, the company's dividend payout ratio is 0.22.\"\n",
      " 'When a stock reaches the target an analyst has set, the analyst logically has two ways to react: downgrade on valuation, or, re-adjust their target price to a higher level. Analyst reaction may also depend on the fundamental business developments that may be responsible for driving the stock price higher — if things are looking up for the company, perhaps it is time for that target price to be raised. There are 14 different analyst targets within the Zacks coverage universe contributing to that average for Agilent Technologies, Inc., but the average is just that — a mathematical average.'\n",
      " ...\n",
      " 'Q2 2012 Financial Results: Strong Revenue and Gross Margin But Op Expenses Remain High… Brian Marckx, CFA Zynex Inc (ZYXI) reported financial results for second quarter ending June 30, 2012 on August 7th. Please visit scr.zacks.com to access a free copy of the ZYXI research report. ZYNEX INC (ZYXI): Free Stock Analysis Report To read this article on Zacks.com click here.'\n",
      " '35% Revenue Growth in Q1 Brian Marckx, CFA Revenue Zynex Inc. (ZYXI) reported financial results for the first quarter ending March 31, 2012 on May 8th. ZYNEX INC (ZYXI): Free Stock Analysis Report To read this article on Zacks.com click here. We continue to model strong growth in products sales coming from further expansion in the sales force, incremental contribution from the recent NeuroDyne acquisition, the recurring revenue stream from consumables (over an ever larger installed base), and introduction of new products in the Zynex Medical (i.e. - electrotherapy) business.'\n",
      " \"Q4 2011 Financial Results: Largely In-Line with Our Numbers... Brian Marckx, CFA Revenue Zynex Inc. (ZYXI) reported financial results for the fourth quarter ending December 31, 2011 on March 15th. ZYXI did a good job of doing exactly that throughout 2011, with SG&A as % of sales falling from 71.9% in 2010 to 69.3% in 2011. To view a free copy of our most recent research report on ZYXIor subscribe to our daily morning email alert, visit Brian Marckx's coverage page at http://scr.zacks.com/ .\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the unique values of every column and their counts\n",
    "for col in news_df.columns:\n",
    "    print(f\"Unique values in {col}: {news_df[col].nunique()}\")\n",
    "    print(news_df[col].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7e9bc9",
   "metadata": {},
   "source": [
    "# News dataset refining (handling missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15497175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Stock_symbol</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Author</th>\n",
       "      <th>Article</th>\n",
       "      <th>Lsa_summary</th>\n",
       "      <th>Luhn_summary</th>\n",
       "      <th>Textrank_summary</th>\n",
       "      <th>Lexrank_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-16 23:00:00 UTC</td>\n",
       "      <td>Interesting A Put And Call Options For August ...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Investors in Agilent Technologies, Inc. (Symbo...</td>\n",
       "      <td>Because the $125.00 strike represents an appro...</td>\n",
       "      <td>The current analytical data (including greeks ...</td>\n",
       "      <td>Below is a chart showing the trailing twelve m...</td>\n",
       "      <td>At Stock Options Channel, our YieldBoost formu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-12 00:00:00 UTC</td>\n",
       "      <td>Wolfe Research Initiates Coverage of Agilent T...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fintel reports that on December 13, 2023, Wolf...</td>\n",
       "      <td>Fintel reports that on December 13, 2023, Wolf...</td>\n",
       "      <td>T. Rowe Price Investment Management holds 10,1...</td>\n",
       "      <td>Agilent Technologies Declares $0.24 Dividend O...</td>\n",
       "      <td>The projected annual revenue for Agilent Techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-12 00:00:00 UTC</td>\n",
       "      <td>Agilent Technologies Reaches Analyst Target Price</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>When a stock reaches the target an analyst has...</td>\n",
       "      <td>When a stock reaches the target an analyst has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-07 00:00:00 UTC</td>\n",
       "      <td>Agilent (A) Enhances BioTek Cytation C10 With ...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agilent Technologies A is enhancing its BioTek...</td>\n",
       "      <td>Per a Grand View Research report, the global m...</td>\n",
       "      <td>Notably, Agilent enhanced the BioTek Cytation ...</td>\n",
       "      <td>Agilent Technologies, Inc. Price and Consensus...</td>\n",
       "      <td>Notably, Agilent enhanced the BioTek Cytation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-07 00:00:00 UTC</td>\n",
       "      <td>Pre-Market Most Active for Dec 7, 2023 : SQQQ,...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The NASDAQ 100 Pre-Market Indicator is up 70.2...</td>\n",
       "      <td>ProShares UltraPro Short QQQ (SQQQ) is -0.15 a...</td>\n",
       "      <td>As reported by Zacks, the current mean recomme...</td>\n",
       "      <td>The total Pre-Market volume is currently 39,23...</td>\n",
       "      <td>The NASDAQ 100 Pre-Market Indicator is up 70.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date                                      Article_title  \\\n",
       "0  2023-12-16 23:00:00 UTC  Interesting A Put And Call Options For August ...   \n",
       "1  2023-12-12 00:00:00 UTC  Wolfe Research Initiates Coverage of Agilent T...   \n",
       "2  2023-12-12 00:00:00 UTC  Agilent Technologies Reaches Analyst Target Price   \n",
       "3  2023-12-07 00:00:00 UTC  Agilent (A) Enhances BioTek Cytation C10 With ...   \n",
       "4  2023-12-07 00:00:00 UTC  Pre-Market Most Active for Dec 7, 2023 : SQQQ,...   \n",
       "\n",
       "  Stock_symbol Publisher Author  \\\n",
       "0            A       NaN    NaN   \n",
       "1            A       NaN    NaN   \n",
       "2            A       NaN    NaN   \n",
       "3            A       NaN    NaN   \n",
       "4            A       NaN    NaN   \n",
       "\n",
       "                                             Article  \\\n",
       "0  Investors in Agilent Technologies, Inc. (Symbo...   \n",
       "1  Fintel reports that on December 13, 2023, Wolf...   \n",
       "2  In recent trading, shares of Agilent Technolog...   \n",
       "3  Agilent Technologies A is enhancing its BioTek...   \n",
       "4  The NASDAQ 100 Pre-Market Indicator is up 70.2...   \n",
       "\n",
       "                                         Lsa_summary  \\\n",
       "0  Because the $125.00 strike represents an appro...   \n",
       "1  Fintel reports that on December 13, 2023, Wolf...   \n",
       "2  In recent trading, shares of Agilent Technolog...   \n",
       "3  Per a Grand View Research report, the global m...   \n",
       "4  ProShares UltraPro Short QQQ (SQQQ) is -0.15 a...   \n",
       "\n",
       "                                        Luhn_summary  \\\n",
       "0  The current analytical data (including greeks ...   \n",
       "1  T. Rowe Price Investment Management holds 10,1...   \n",
       "2  In recent trading, shares of Agilent Technolog...   \n",
       "3  Notably, Agilent enhanced the BioTek Cytation ...   \n",
       "4  As reported by Zacks, the current mean recomme...   \n",
       "\n",
       "                                    Textrank_summary  \\\n",
       "0  Below is a chart showing the trailing twelve m...   \n",
       "1  Agilent Technologies Declares $0.24 Dividend O...   \n",
       "2  When a stock reaches the target an analyst has...   \n",
       "3  Agilent Technologies, Inc. Price and Consensus...   \n",
       "4  The total Pre-Market volume is currently 39,23...   \n",
       "\n",
       "                                     Lexrank_summary  \n",
       "0  At Stock Options Channel, our YieldBoost formu...  \n",
       "1  The projected annual revenue for Agilent Techn...  \n",
       "2  When a stock reaches the target an analyst has...  \n",
       "3  Notably, Agilent enhanced the BioTek Cytation ...  \n",
       "4  The NASDAQ 100 Pre-Market Indicator is up 70.2...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns Unnamed: 0 and Url\n",
    "news_df = news_df.drop(columns=[\"Unnamed: 0\", \"Url\"])\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c233a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15549299\n",
      "5744672\n"
     ]
    }
   ],
   "source": [
    "print(len(news_df))\n",
    "\n",
    "# Drop rows with missing values in date and stock symbol columns\n",
    "news_df = news_df.dropna(subset=[\"Date\", \"Stock_symbol\"])\n",
    "\n",
    "print(len(news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a2cd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5744672\n",
      "5744672\n"
     ]
    }
   ],
   "source": [
    "print(len(news_df))\n",
    "\n",
    "# Drop rows only if they have missing values in each of these columns: Article_title, Publisher, Author, Article, Lsa_summary, Luhn_summary, Textrank_summary, Lexrank_summary\n",
    "news_df = news_df.dropna(subset=[\"Article_title\", \"Publisher\", \"Author\", \"Article\", \"Lsa_summary\", \"Luhn_summary\", \"Textrank_summary\", \"Lexrank_summary\"], how=\"all\")\n",
    "\n",
    "print(len(news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b09b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill all missing values of the Article_title, Publisher, Author, Article, Lsa_summary, Luhn_summary, Textrank_summary, Lexrank_summary columns with \"Unknown\"\n",
    "news_df[[\"Article_title\", \"Publisher\", \"Author\", \"Article\", \"Lsa_summary\", \"Luhn_summary\", \"Textrank_summary\", \"Lexrank_summary\"]] = news_df[[\"Article_title\", \"Publisher\", \"Author\", \"Article\", \"Lsa_summary\", \"Luhn_summary\", \"Textrank_summary\", \"Lexrank_summary\"]].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6e7ecee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any missing values in the DataFrame\n",
    "missing_values = news_df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9036290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Stock_symbol</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Author</th>\n",
       "      <th>Article</th>\n",
       "      <th>Lsa_summary</th>\n",
       "      <th>Luhn_summary</th>\n",
       "      <th>Textrank_summary</th>\n",
       "      <th>Lexrank_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-16 23:00:00 UTC</td>\n",
       "      <td>Interesting A Put And Call Options For August ...</td>\n",
       "      <td>A</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Investors in Agilent Technologies, Inc. (Symbo...</td>\n",
       "      <td>Because the $125.00 strike represents an appro...</td>\n",
       "      <td>The current analytical data (including greeks ...</td>\n",
       "      <td>Below is a chart showing the trailing twelve m...</td>\n",
       "      <td>At Stock Options Channel, our YieldBoost formu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-12 00:00:00 UTC</td>\n",
       "      <td>Wolfe Research Initiates Coverage of Agilent T...</td>\n",
       "      <td>A</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fintel reports that on December 13, 2023, Wolf...</td>\n",
       "      <td>Fintel reports that on December 13, 2023, Wolf...</td>\n",
       "      <td>T. Rowe Price Investment Management holds 10,1...</td>\n",
       "      <td>Agilent Technologies Declares $0.24 Dividend O...</td>\n",
       "      <td>The projected annual revenue for Agilent Techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-12 00:00:00 UTC</td>\n",
       "      <td>Agilent Technologies Reaches Analyst Target Price</td>\n",
       "      <td>A</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>When a stock reaches the target an analyst has...</td>\n",
       "      <td>When a stock reaches the target an analyst has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-07 00:00:00 UTC</td>\n",
       "      <td>Agilent (A) Enhances BioTek Cytation C10 With ...</td>\n",
       "      <td>A</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Agilent Technologies A is enhancing its BioTek...</td>\n",
       "      <td>Per a Grand View Research report, the global m...</td>\n",
       "      <td>Notably, Agilent enhanced the BioTek Cytation ...</td>\n",
       "      <td>Agilent Technologies, Inc. Price and Consensus...</td>\n",
       "      <td>Notably, Agilent enhanced the BioTek Cytation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-07 00:00:00 UTC</td>\n",
       "      <td>Pre-Market Most Active for Dec 7, 2023 : SQQQ,...</td>\n",
       "      <td>A</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The NASDAQ 100 Pre-Market Indicator is up 70.2...</td>\n",
       "      <td>ProShares UltraPro Short QQQ (SQQQ) is -0.15 a...</td>\n",
       "      <td>As reported by Zacks, the current mean recomme...</td>\n",
       "      <td>The total Pre-Market volume is currently 39,23...</td>\n",
       "      <td>The NASDAQ 100 Pre-Market Indicator is up 70.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date                                      Article_title  \\\n",
       "0  2023-12-16 23:00:00 UTC  Interesting A Put And Call Options For August ...   \n",
       "1  2023-12-12 00:00:00 UTC  Wolfe Research Initiates Coverage of Agilent T...   \n",
       "2  2023-12-12 00:00:00 UTC  Agilent Technologies Reaches Analyst Target Price   \n",
       "3  2023-12-07 00:00:00 UTC  Agilent (A) Enhances BioTek Cytation C10 With ...   \n",
       "4  2023-12-07 00:00:00 UTC  Pre-Market Most Active for Dec 7, 2023 : SQQQ,...   \n",
       "\n",
       "  Stock_symbol Publisher   Author  \\\n",
       "0            A   Unknown  Unknown   \n",
       "1            A   Unknown  Unknown   \n",
       "2            A   Unknown  Unknown   \n",
       "3            A   Unknown  Unknown   \n",
       "4            A   Unknown  Unknown   \n",
       "\n",
       "                                             Article  \\\n",
       "0  Investors in Agilent Technologies, Inc. (Symbo...   \n",
       "1  Fintel reports that on December 13, 2023, Wolf...   \n",
       "2  In recent trading, shares of Agilent Technolog...   \n",
       "3  Agilent Technologies A is enhancing its BioTek...   \n",
       "4  The NASDAQ 100 Pre-Market Indicator is up 70.2...   \n",
       "\n",
       "                                         Lsa_summary  \\\n",
       "0  Because the $125.00 strike represents an appro...   \n",
       "1  Fintel reports that on December 13, 2023, Wolf...   \n",
       "2  In recent trading, shares of Agilent Technolog...   \n",
       "3  Per a Grand View Research report, the global m...   \n",
       "4  ProShares UltraPro Short QQQ (SQQQ) is -0.15 a...   \n",
       "\n",
       "                                        Luhn_summary  \\\n",
       "0  The current analytical data (including greeks ...   \n",
       "1  T. Rowe Price Investment Management holds 10,1...   \n",
       "2  In recent trading, shares of Agilent Technolog...   \n",
       "3  Notably, Agilent enhanced the BioTek Cytation ...   \n",
       "4  As reported by Zacks, the current mean recomme...   \n",
       "\n",
       "                                    Textrank_summary  \\\n",
       "0  Below is a chart showing the trailing twelve m...   \n",
       "1  Agilent Technologies Declares $0.24 Dividend O...   \n",
       "2  When a stock reaches the target an analyst has...   \n",
       "3  Agilent Technologies, Inc. Price and Consensus...   \n",
       "4  The total Pre-Market volume is currently 39,23...   \n",
       "\n",
       "                                     Lexrank_summary  \n",
       "0  At Stock Options Channel, our YieldBoost formu...  \n",
       "1  The projected annual revenue for Agilent Techn...  \n",
       "2  When a stock reaches the target an analyst has...  \n",
       "3  Notably, Agilent enhanced the BioTek Cytation ...  \n",
       "4  The NASDAQ 100 Pre-Market Indicator is up 70.2...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaf2562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the date column to only keep the date part keep only the first 10 characters\n",
    "news_df[\"Date\"] = news_df[\"Date\"].str[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "486bb481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Article_title</th>\n",
       "      <th>Stock_symbol</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Author</th>\n",
       "      <th>Article</th>\n",
       "      <th>Lsa_summary</th>\n",
       "      <th>Luhn_summary</th>\n",
       "      <th>Textrank_summary</th>\n",
       "      <th>Lexrank_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>Interesting A Put And Call Options For August ...</td>\n",
       "      <td>A</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Investors in Agilent Technologies, Inc. (Symbo...</td>\n",
       "      <td>Because the $125.00 strike represents an appro...</td>\n",
       "      <td>The current analytical data (including greeks ...</td>\n",
       "      <td>Below is a chart showing the trailing twelve m...</td>\n",
       "      <td>At Stock Options Channel, our YieldBoost formu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>Wolfe Research Initiates Coverage of Agilent T...</td>\n",
       "      <td>A</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fintel reports that on December 13, 2023, Wolf...</td>\n",
       "      <td>Fintel reports that on December 13, 2023, Wolf...</td>\n",
       "      <td>T. Rowe Price Investment Management holds 10,1...</td>\n",
       "      <td>Agilent Technologies Declares $0.24 Dividend O...</td>\n",
       "      <td>The projected annual revenue for Agilent Techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>Agilent Technologies Reaches Analyst Target Price</td>\n",
       "      <td>A</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>In recent trading, shares of Agilent Technolog...</td>\n",
       "      <td>When a stock reaches the target an analyst has...</td>\n",
       "      <td>When a stock reaches the target an analyst has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>Agilent (A) Enhances BioTek Cytation C10 With ...</td>\n",
       "      <td>A</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Agilent Technologies A is enhancing its BioTek...</td>\n",
       "      <td>Per a Grand View Research report, the global m...</td>\n",
       "      <td>Notably, Agilent enhanced the BioTek Cytation ...</td>\n",
       "      <td>Agilent Technologies, Inc. Price and Consensus...</td>\n",
       "      <td>Notably, Agilent enhanced the BioTek Cytation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>Pre-Market Most Active for Dec 7, 2023 : SQQQ,...</td>\n",
       "      <td>A</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The NASDAQ 100 Pre-Market Indicator is up 70.2...</td>\n",
       "      <td>ProShares UltraPro Short QQQ (SQQQ) is -0.15 a...</td>\n",
       "      <td>As reported by Zacks, the current mean recomme...</td>\n",
       "      <td>The total Pre-Market volume is currently 39,23...</td>\n",
       "      <td>The NASDAQ 100 Pre-Market Indicator is up 70.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date                                      Article_title Stock_symbol  \\\n",
       "0  2023-12-16  Interesting A Put And Call Options For August ...            A   \n",
       "1  2023-12-12  Wolfe Research Initiates Coverage of Agilent T...            A   \n",
       "2  2023-12-12  Agilent Technologies Reaches Analyst Target Price            A   \n",
       "3  2023-12-07  Agilent (A) Enhances BioTek Cytation C10 With ...            A   \n",
       "4  2023-12-07  Pre-Market Most Active for Dec 7, 2023 : SQQQ,...            A   \n",
       "\n",
       "  Publisher   Author                                            Article  \\\n",
       "0   Unknown  Unknown  Investors in Agilent Technologies, Inc. (Symbo...   \n",
       "1   Unknown  Unknown  Fintel reports that on December 13, 2023, Wolf...   \n",
       "2   Unknown  Unknown  In recent trading, shares of Agilent Technolog...   \n",
       "3   Unknown  Unknown  Agilent Technologies A is enhancing its BioTek...   \n",
       "4   Unknown  Unknown  The NASDAQ 100 Pre-Market Indicator is up 70.2...   \n",
       "\n",
       "                                         Lsa_summary  \\\n",
       "0  Because the $125.00 strike represents an appro...   \n",
       "1  Fintel reports that on December 13, 2023, Wolf...   \n",
       "2  In recent trading, shares of Agilent Technolog...   \n",
       "3  Per a Grand View Research report, the global m...   \n",
       "4  ProShares UltraPro Short QQQ (SQQQ) is -0.15 a...   \n",
       "\n",
       "                                        Luhn_summary  \\\n",
       "0  The current analytical data (including greeks ...   \n",
       "1  T. Rowe Price Investment Management holds 10,1...   \n",
       "2  In recent trading, shares of Agilent Technolog...   \n",
       "3  Notably, Agilent enhanced the BioTek Cytation ...   \n",
       "4  As reported by Zacks, the current mean recomme...   \n",
       "\n",
       "                                    Textrank_summary  \\\n",
       "0  Below is a chart showing the trailing twelve m...   \n",
       "1  Agilent Technologies Declares $0.24 Dividend O...   \n",
       "2  When a stock reaches the target an analyst has...   \n",
       "3  Agilent Technologies, Inc. Price and Consensus...   \n",
       "4  The total Pre-Market volume is currently 39,23...   \n",
       "\n",
       "                                     Lexrank_summary  \n",
       "0  At Stock Options Channel, our YieldBoost formu...  \n",
       "1  The projected annual revenue for Agilent Techn...  \n",
       "2  When a stock reaches the target an analyst has...  \n",
       "3  Notably, Agilent enhanced the BioTek Cytation ...  \n",
       "4  The NASDAQ 100 Pre-Market Indicator is up 70.2...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23ca4518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5744672/5744672 [04:41<00:00, 20392.74it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Columns to include in Input_text\n",
    "cols_to_use = [col for col in news_df.columns if col not in [\"Date\", \"Stock_symbol\"]]\n",
    "\n",
    "def create_input_text_fast(row):\n",
    "    return \"\\n\".join(f\"{col}: {getattr(row, col)}\" for col in cols_to_use)\n",
    "\n",
    "# Create Input_text using itertuples for better performance and memory usage\n",
    "input_texts = []\n",
    "for row in tqdm(news_df.itertuples(index=False), total=len(news_df)):\n",
    "    input_texts.append(create_input_text_fast(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71347f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_symbol</th>\n",
       "      <th>Input_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-12-16</td>\n",
       "      <td>A</td>\n",
       "      <td>Article_title: Interesting A Put And Call Opti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>A</td>\n",
       "      <td>Article_title: Wolfe Research Initiates Covera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>A</td>\n",
       "      <td>Article_title: Agilent Technologies Reaches An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>A</td>\n",
       "      <td>Article_title: Agilent (A) Enhances BioTek Cyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-12-07</td>\n",
       "      <td>A</td>\n",
       "      <td>Article_title: Pre-Market Most Active for Dec ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Stock_symbol                                         Input_text\n",
       "0  2023-12-16            A  Article_title: Interesting A Put And Call Opti...\n",
       "1  2023-12-12            A  Article_title: Wolfe Research Initiates Covera...\n",
       "2  2023-12-12            A  Article_title: Agilent Technologies Reaches An...\n",
       "3  2023-12-07            A  Article_title: Agilent (A) Enhances BioTek Cyt...\n",
       "4  2023-12-07            A  Article_title: Pre-Market Most Active for Dec ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the new column\n",
    "news_df[\"Input_text\"] = input_texts\n",
    "\n",
    "# Drop unused columns\n",
    "news_df = news_df.drop(columns=[\n",
    "    \"Article_title\", \"Publisher\", \"Author\", \"Article\", \n",
    "    \"Lsa_summary\", \"Luhn_summary\", \"Textrank_summary\", \"Lexrank_summary\"\n",
    "])\n",
    "\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec350a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "news_df.to_csv(\"../data/news/processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86ac61",
   "metadata": {},
   "source": [
    "# Processed news loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0c6d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'AAL', 'AAP', 'AAPL', 'ABC', 'ABMD', 'ABT', 'ACN', 'ADI', 'ADM', 'ADP', 'ADSK', 'AEE', 'AEP', 'AIZ', 'AJG', 'AKAM', 'ALB', 'ALGN', 'ALK', 'AMAT', 'AMD', 'AME', 'AMGN', 'AMP', 'AMT', 'AMZN', 'AON', 'AOS', 'APA', 'APD', 'APH', 'ARE', 'ATVI', 'AVB', 'AVY', 'AXP', 'AZO', 'BA', 'BAC', 'BAX', 'BBY', 'BDX', 'BEN', 'BF-A', 'BIIB', 'BIO', 'BK', 'BLK', 'BMRA', 'BMY', 'BR', 'BRK-A', 'BSX', 'BWA', 'BXP', 'C', 'CAG', 'CAH', 'CAT', 'CB', 'CCI', 'CDE', 'CDNS', 'CF', 'CHD', 'CHRW', 'CINF', 'CL', 'CLX', 'CME', 'CMG', 'CMI', 'CNC', 'CNP', 'COO', 'COP', 'COST', 'COWN', 'CPB', 'CPRT', 'CRM', 'CSCO', 'CTAS', 'CTSH', 'CUK', 'D', 'DAL', 'DE', 'DFS', 'DGX', 'DHI', 'DIS', 'DLTR', 'DOV', 'DPZ', 'DRI', 'DTE', 'DVA', 'DXCM', 'EA', 'EBAY', 'ECL', 'ED', 'EFX', 'EIX', 'EL', 'EMN', 'EMR', 'ENS', 'EOG', 'EQIX', 'EQR', 'ES', 'ESS', 'EW', 'EXR', 'F', 'FAST', 'FCX', 'FDX', 'FE', 'FFIV', 'FIS', 'FISV', 'FITB', 'FLS', 'FMC', 'FRT', 'FTI', 'GD', 'GE', 'GGG', 'GILD', 'GIS', 'GOOG', 'GPC', 'GPN', 'GRMN', 'GWW', 'HAL', 'HAS', 'HBAN', 'HBI', 'HD', 'HES', 'HOLX', 'HON', 'HPQ', 'HRB', 'HRL', 'HSIC', 'HST', 'HSY', 'HTLF', 'HUM', 'IBM', 'ICE', 'IDXX', 'IEX', 'IFF', 'ILMN', 'INTU', 'IP', 'IPGP', 'IRM', 'ISRG', 'IT', 'ITW', 'IVZ', 'JBHT', 'JCI', 'JKHY', 'JNJ', 'JNPR', 'JPM', 'K', 'KEY', 'KIM', 'KMB', 'KMX', 'KO', 'KR', 'KSS', 'LBTYA', 'LDOS', 'LEG', 'LH', 'LKQ', 'LMT', 'LNC', 'LNT', 'LOW', 'LRCX', 'LUV', 'LVS', 'LYV', 'MAA', 'MAR', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MDT', 'MET', 'MGM', 'MHK', 'MKTX', 'MLM', 'MMC', 'MMM', 'MNST', 'MO', 'MOS', 'MRK', 'MRO', 'MSFT', 'MSI', 'MU', 'NDAQ', 'NEE', 'NEOG', 'NFLX', 'NI', 'NOC', 'NOK', 'NOV', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NVR', 'NWL', 'O', 'ODFL', 'OKE', 'OMC', 'ORLY', 'OXY', 'PAYX', 'PCAR', 'PEG', 'PEP', 'PFE', 'PG', 'PH', 'PHM', 'PKG', 'PKI', 'PLD', 'PNR', 'PNW', 'PPG', 'PRU', 'PVH', 'PWR', 'PXD', 'RCL', 'RE', 'REG', 'REGN', 'RF', 'RHI', 'RIBT', 'RJF', 'RL', 'RLI', 'RMD', 'ROK', 'ROL', 'ROP', 'ROST', 'RSG', 'SBUX', 'SCHW', 'SEE', 'SEGXF', 'SHW', 'SIVB', 'SLB', 'SLG', 'SNPS', 'SO', 'SPG', 'SRE', 'STT', 'STX', 'SWK', 'SWKS', 'SYK', 'T', 'TAP', 'TEL', 'TJX', 'TMO', 'TMUS', 'TROW', 'TRV', 'TSCO', 'TSN', 'TTWO', 'TXN', 'TXT', 'TYL', 'UAL', 'UDR', 'UEEC', 'UHS', 'UNM', 'UNP', 'UPS', 'URI', 'USB', 'VFC', 'VMC', 'VRSN', 'VTR', 'VZ', 'WAT', 'WBA', 'WDC', 'WEC', 'WHR', 'WM', 'WMB', 'WRB', 'WST', 'WU', 'WY', 'WYNN', 'XEL', 'XOM', 'YUM', 'ZBH', 'ZION']\n",
      "336\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load list of stock symbols from the file\n",
    "stock_symbols = [f[:-4] for f in os.listdir(\"../data/normalized/sp500/csv\") if f.endswith(\".csv\")]\n",
    "# Remove the .DS_Store file if it exists\n",
    "if \".DS_Store\" in stock_symbols:\n",
    "    stock_symbols.remove(\".DS_Store\")\n",
    "\n",
    "print(stock_symbols)\n",
    "print(len(stock_symbols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f77687",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/news/processed.csv\"\n",
    "\n",
    "news_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100f29ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5744672\n",
      "1016283\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where Stock_symbol is not in the list of stock symbols\n",
    "print(len(news_df))\n",
    "news_df = news_df[news_df[\"Stock_symbol\"].isin(stock_symbols)]\n",
    "print(len(news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b68d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing stock symbol: A\n",
      "Processing stock symbol: AAL\n",
      "Processing stock symbol: AAP\n",
      "Processing stock symbol: AAPL\n",
      "Processing stock symbol: ABC\n",
      "Processing stock symbol: ABMD\n",
      "Processing stock symbol: ABT\n",
      "Processing stock symbol: ACN\n",
      "Processing stock symbol: ADI\n",
      "Processing stock symbol: ADM\n",
      "Processing stock symbol: ADP\n",
      "Processing stock symbol: ADSK\n",
      "Processing stock symbol: AEE\n",
      "Processing stock symbol: AEP\n",
      "Processing stock symbol: AIZ\n",
      "Processing stock symbol: AJG\n",
      "Processing stock symbol: AKAM\n",
      "Processing stock symbol: ALB\n",
      "Processing stock symbol: ALGN\n",
      "Processing stock symbol: ALK\n",
      "Processing stock symbol: AMAT\n",
      "Processing stock symbol: AMD\n",
      "Processing stock symbol: AME\n",
      "Processing stock symbol: AMGN\n",
      "Processing stock symbol: AMP\n",
      "Processing stock symbol: AMT\n",
      "Processing stock symbol: AMZN\n",
      "Processing stock symbol: AON\n",
      "Processing stock symbol: AOS\n",
      "Processing stock symbol: APA\n",
      "Processing stock symbol: APD\n",
      "Processing stock symbol: APH\n",
      "Processing stock symbol: ARE\n",
      "Processing stock symbol: ATVI\n",
      "Processing stock symbol: AVB\n",
      "Processing stock symbol: AVY\n",
      "Processing stock symbol: AXP\n",
      "Processing stock symbol: AZO\n",
      "Processing stock symbol: BA\n",
      "Processing stock symbol: BAC\n",
      "Processing stock symbol: BAX\n",
      "Processing stock symbol: BBY\n",
      "Processing stock symbol: BDX\n",
      "Processing stock symbol: BEN\n",
      "Processing stock symbol: BF-A\n",
      "Processing stock symbol: BIIB\n",
      "Processing stock symbol: BIO\n",
      "Processing stock symbol: BK\n",
      "Processing stock symbol: BLK\n",
      "Processing stock symbol: BMRA\n",
      "Processing stock symbol: BMY\n",
      "Processing stock symbol: BR\n",
      "Processing stock symbol: BRK-A\n",
      "Processing stock symbol: BSX\n",
      "Processing stock symbol: BWA\n",
      "Processing stock symbol: BXP\n",
      "Processing stock symbol: C\n",
      "Processing stock symbol: CAG\n",
      "Processing stock symbol: CAH\n",
      "Processing stock symbol: CAT\n",
      "Processing stock symbol: CB\n",
      "Processing stock symbol: CCI\n",
      "Processing stock symbol: CDE\n",
      "Processing stock symbol: CDNS\n",
      "Processing stock symbol: CF\n",
      "Processing stock symbol: CHD\n",
      "Processing stock symbol: CHRW\n",
      "Processing stock symbol: CINF\n",
      "Processing stock symbol: CL\n",
      "Processing stock symbol: CLX\n",
      "Processing stock symbol: CME\n",
      "Processing stock symbol: CMG\n",
      "Processing stock symbol: CMI\n",
      "Processing stock symbol: CNC\n",
      "Processing stock symbol: CNP\n",
      "Processing stock symbol: COO\n",
      "Processing stock symbol: COP\n",
      "Processing stock symbol: COST\n",
      "Processing stock symbol: COWN\n",
      "Processing stock symbol: CPB\n",
      "Processing stock symbol: CPRT\n",
      "Processing stock symbol: CRM\n",
      "Processing stock symbol: CSCO\n",
      "Processing stock symbol: CTAS\n",
      "Processing stock symbol: CTSH\n",
      "Processing stock symbol: CUK\n",
      "Processing stock symbol: D\n",
      "Processing stock symbol: DAL\n",
      "Processing stock symbol: DE\n",
      "Processing stock symbol: DFS\n",
      "Processing stock symbol: DGX\n",
      "Processing stock symbol: DHI\n",
      "Processing stock symbol: DIS\n",
      "Processing stock symbol: DLTR\n",
      "Processing stock symbol: DOV\n",
      "Processing stock symbol: DPZ\n",
      "Processing stock symbol: DRI\n",
      "Processing stock symbol: DTE\n",
      "Processing stock symbol: DVA\n",
      "Processing stock symbol: DXCM\n",
      "Processing stock symbol: EA\n",
      "Processing stock symbol: EBAY\n",
      "Processing stock symbol: ECL\n",
      "Processing stock symbol: ED\n",
      "Processing stock symbol: EFX\n",
      "Processing stock symbol: EIX\n",
      "Processing stock symbol: EL\n",
      "Processing stock symbol: EMN\n",
      "Processing stock symbol: EMR\n",
      "Processing stock symbol: ENS\n",
      "Processing stock symbol: EOG\n",
      "Processing stock symbol: EQIX\n",
      "Processing stock symbol: EQR\n",
      "Processing stock symbol: ES\n",
      "Processing stock symbol: ESS\n",
      "Processing stock symbol: EW\n",
      "Processing stock symbol: EXR\n",
      "Processing stock symbol: F\n",
      "Processing stock symbol: FAST\n",
      "Processing stock symbol: FCX\n",
      "Processing stock symbol: FDX\n",
      "Processing stock symbol: FE\n",
      "Processing stock symbol: FFIV\n",
      "Processing stock symbol: FIS\n",
      "Processing stock symbol: FISV\n",
      "Processing stock symbol: FITB\n",
      "Processing stock symbol: FLS\n",
      "Processing stock symbol: FMC\n",
      "Processing stock symbol: FRT\n",
      "Processing stock symbol: FTI\n",
      "Processing stock symbol: GD\n",
      "Processing stock symbol: GE\n",
      "Processing stock symbol: GGG\n",
      "Processing stock symbol: GILD\n",
      "Processing stock symbol: GIS\n",
      "Processing stock symbol: GOOG\n",
      "Processing stock symbol: GPC\n",
      "Processing stock symbol: GPN\n",
      "Processing stock symbol: GRMN\n",
      "Processing stock symbol: GWW\n",
      "Processing stock symbol: HAL\n",
      "Processing stock symbol: HAS\n",
      "Processing stock symbol: HBAN\n",
      "Processing stock symbol: HBI\n",
      "Processing stock symbol: HD\n",
      "Processing stock symbol: HES\n",
      "Processing stock symbol: HOLX\n",
      "Processing stock symbol: HON\n",
      "Processing stock symbol: HPQ\n",
      "Processing stock symbol: HRB\n",
      "Processing stock symbol: HRL\n",
      "Processing stock symbol: HSIC\n",
      "Processing stock symbol: HST\n",
      "Processing stock symbol: HSY\n",
      "Processing stock symbol: HTLF\n",
      "Processing stock symbol: HUM\n",
      "Processing stock symbol: IBM\n",
      "Processing stock symbol: ICE\n",
      "Processing stock symbol: IDXX\n",
      "Processing stock symbol: IEX\n",
      "Processing stock symbol: IFF\n",
      "Processing stock symbol: ILMN\n",
      "Processing stock symbol: INTU\n",
      "Processing stock symbol: IP\n",
      "Processing stock symbol: IPGP\n",
      "Processing stock symbol: IRM\n",
      "Processing stock symbol: ISRG\n",
      "Processing stock symbol: IT\n",
      "Processing stock symbol: ITW\n",
      "Processing stock symbol: IVZ\n",
      "Processing stock symbol: JBHT\n",
      "Processing stock symbol: JCI\n",
      "Processing stock symbol: JKHY\n",
      "Processing stock symbol: JNJ\n",
      "Processing stock symbol: JNPR\n",
      "Processing stock symbol: JPM\n",
      "Processing stock symbol: K\n",
      "Processing stock symbol: KEY\n",
      "Processing stock symbol: KIM\n",
      "Processing stock symbol: KMB\n",
      "Processing stock symbol: KMX\n",
      "Processing stock symbol: KO\n",
      "Processing stock symbol: KR\n",
      "Processing stock symbol: KSS\n",
      "Processing stock symbol: LBTYA\n",
      "Processing stock symbol: LDOS\n",
      "Processing stock symbol: LEG\n",
      "Processing stock symbol: LH\n",
      "Processing stock symbol: LKQ\n",
      "Processing stock symbol: LMT\n",
      "Processing stock symbol: LNC\n",
      "Processing stock symbol: LNT\n",
      "Processing stock symbol: LOW\n",
      "Processing stock symbol: LRCX\n",
      "Processing stock symbol: LUV\n",
      "Processing stock symbol: LVS\n",
      "Processing stock symbol: LYV\n",
      "Processing stock symbol: MAA\n",
      "Processing stock symbol: MAR\n",
      "Processing stock symbol: MCD\n",
      "Processing stock symbol: MCHP\n",
      "Processing stock symbol: MCK\n",
      "Processing stock symbol: MCO\n",
      "Processing stock symbol: MDLZ\n",
      "Processing stock symbol: MDT\n",
      "Processing stock symbol: MET\n",
      "Processing stock symbol: MGM\n",
      "Processing stock symbol: MHK\n",
      "Processing stock symbol: MKTX\n",
      "Processing stock symbol: MLM\n",
      "Processing stock symbol: MMC\n",
      "Processing stock symbol: MMM\n",
      "Processing stock symbol: MNST\n",
      "Processing stock symbol: MO\n",
      "Processing stock symbol: MOS\n",
      "Processing stock symbol: MRK\n",
      "Processing stock symbol: MRO\n",
      "Processing stock symbol: MSFT\n",
      "Processing stock symbol: MSI\n",
      "Processing stock symbol: MU\n",
      "Processing stock symbol: NDAQ\n",
      "Processing stock symbol: NEE\n",
      "Processing stock symbol: NEOG\n",
      "Processing stock symbol: NFLX\n",
      "Processing stock symbol: NI\n",
      "Processing stock symbol: NOC\n",
      "Processing stock symbol: NOK\n",
      "Processing stock symbol: NOV\n",
      "Processing stock symbol: NRG\n",
      "Processing stock symbol: NSC\n",
      "Processing stock symbol: NTAP\n",
      "Processing stock symbol: NTRS\n",
      "Processing stock symbol: NVR\n",
      "Processing stock symbol: NWL\n",
      "Processing stock symbol: O\n",
      "Processing stock symbol: ODFL\n",
      "Processing stock symbol: OKE\n",
      "Processing stock symbol: OMC\n",
      "Processing stock symbol: ORLY\n",
      "Processing stock symbol: OXY\n",
      "Processing stock symbol: PAYX\n",
      "Processing stock symbol: PCAR\n",
      "Processing stock symbol: PEG\n",
      "Processing stock symbol: PEP\n",
      "Processing stock symbol: PFE\n",
      "Processing stock symbol: PG\n",
      "Processing stock symbol: PH\n",
      "Processing stock symbol: PHM\n",
      "Processing stock symbol: PKG\n",
      "Processing stock symbol: PKI\n",
      "Processing stock symbol: PLD\n",
      "Processing stock symbol: PNR\n",
      "Processing stock symbol: PNW\n",
      "Processing stock symbol: PPG\n",
      "Processing stock symbol: PRU\n",
      "Processing stock symbol: PVH\n",
      "Processing stock symbol: PWR\n",
      "Processing stock symbol: PXD\n",
      "Processing stock symbol: RCL\n",
      "Processing stock symbol: RE\n",
      "Processing stock symbol: REG\n",
      "Processing stock symbol: REGN\n",
      "Processing stock symbol: RF\n",
      "Processing stock symbol: RHI\n",
      "Processing stock symbol: RIBT\n",
      "Processing stock symbol: RJF\n",
      "Processing stock symbol: RL\n",
      "Processing stock symbol: RLI\n",
      "Processing stock symbol: RMD\n",
      "Processing stock symbol: ROK\n",
      "Processing stock symbol: ROL\n",
      "Processing stock symbol: ROP\n",
      "Processing stock symbol: ROST\n",
      "Processing stock symbol: RSG\n",
      "Processing stock symbol: SBUX\n",
      "Processing stock symbol: SCHW\n",
      "Processing stock symbol: SEE\n",
      "Processing stock symbol: SEGXF\n",
      "Processing stock symbol: SHW\n",
      "Processing stock symbol: SIVB\n",
      "Processing stock symbol: SLB\n",
      "Processing stock symbol: SLG\n",
      "Processing stock symbol: SNPS\n",
      "Processing stock symbol: SO\n",
      "Processing stock symbol: SPG\n",
      "Processing stock symbol: SRE\n",
      "Processing stock symbol: STT\n",
      "Processing stock symbol: STX\n",
      "Processing stock symbol: SWK\n",
      "Processing stock symbol: SWKS\n",
      "Processing stock symbol: SYK\n",
      "Processing stock symbol: T\n",
      "Processing stock symbol: TAP\n",
      "Processing stock symbol: TEL\n",
      "Processing stock symbol: TJX\n",
      "Processing stock symbol: TMO\n",
      "Processing stock symbol: TMUS\n",
      "Processing stock symbol: TROW\n",
      "Processing stock symbol: TRV\n",
      "Processing stock symbol: TSCO\n",
      "Processing stock symbol: TSN\n",
      "Processing stock symbol: TTWO\n",
      "Processing stock symbol: TXN\n",
      "Processing stock symbol: TXT\n",
      "Processing stock symbol: TYL\n",
      "Processing stock symbol: UAL\n",
      "Processing stock symbol: UDR\n",
      "Processing stock symbol: UEEC\n",
      "Processing stock symbol: UHS\n",
      "Processing stock symbol: UNM\n",
      "Processing stock symbol: UNP\n",
      "Processing stock symbol: UPS\n",
      "Processing stock symbol: URI\n",
      "Processing stock symbol: USB\n",
      "Processing stock symbol: VFC\n",
      "Processing stock symbol: VMC\n",
      "Processing stock symbol: VRSN\n",
      "Processing stock symbol: VTR\n",
      "Processing stock symbol: VZ\n",
      "Processing stock symbol: WAT\n",
      "Processing stock symbol: WBA\n",
      "Processing stock symbol: WDC\n",
      "Processing stock symbol: WEC\n",
      "Processing stock symbol: WHR\n",
      "Processing stock symbol: WM\n",
      "Processing stock symbol: WMB\n",
      "Processing stock symbol: WRB\n",
      "Processing stock symbol: WST\n",
      "Processing stock symbol: WU\n",
      "Processing stock symbol: WY\n",
      "Processing stock symbol: WYNN\n",
      "Processing stock symbol: XEL\n",
      "Processing stock symbol: XOM\n",
      "Processing stock symbol: YUM\n",
      "Processing stock symbol: ZBH\n",
      "Processing stock symbol: ZION\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the stock symbols and create a separate CSV file for each\n",
    "for stock_symbol in stock_symbols:\n",
    "    print(\"Processing stock symbol:\", stock_symbol)\n",
    "    # Filter the DataFrame for the current stock symbol\n",
    "    filtered_df = news_df[news_df[\"Stock_symbol\"] == stock_symbol]\n",
    "    \n",
    "    # Save the filtered DataFrame to a CSV file\n",
    "    filtered_df.to_csv(f\"../data/news/single_stocks/{stock_symbol}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a4333",
   "metadata": {},
   "source": [
    "# FinBert model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bd00739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9eed2fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article_title: Interesting A Put And Call Options For August 2024\n",
      "Publisher: Unknown\n",
      "Author: Unknown\n",
      "Article: Investors in Agilent Technologies, Inc. (Symbol: A) saw new options begin trading this week, for the August 2024 expiration. One of the key inputs that goes into the price an option buyer is willing to pay, is the time value, so with 241 days until expiration the newly trading contracts represent a possible opportunity for sellers of puts or calls to achieve a higher premium than would be available for the contracts with a closer expiration. At Stock Options Channel, our YieldBoost formula has looked up and down the A options chain for the new August 2024 contracts and identified one put and one call contract of particular interest.\n",
      "The put contract at the $125.00 strike price has a current bid of $4.50. If an investor was to sell-to-open that put contract, they are committing to purchase the stock at $125.00, but will also collect the premium, putting the cost basis of the shares at $120.50 (before broker commissions). To an investor already interested in purchasing shares of A, that could represent an attractive alternative to paying $138.99/share today.\n",
      "Because the $125.00 strike represents an approximate 10% discount to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the put contract would expire worthless. The current analytical data (including greeks and implied greeks) suggest the current odds of that happening are 77%. Stock Options Channel will track those odds over time to see how they change, publishing a chart of those numbers on our website under the contract detail page for this contract. Should the contract expire worthless, the premium would represent a 3.60% return on the cash commitment, or 5.45% annualized — at Stock Options Channel we call this the YieldBoost.\n",
      "Below is a chart showing the trailing twelve month trading history for Agilent Technologies, Inc., and highlighting in green where the $125.00 strike is located relative to that history:\n",
      "Turning to the calls side of the option chain, the call contract at the $150.00 strike price has a current bid of $8.10. If an investor was to purchase shares of A stock at the current price level of $138.99/share, and then sell-to-open that call contract as a \"covered call,\" they are committing to sell the stock at $150.00. Considering the call seller will also collect the premium, that would drive a total return (excluding dividends, if any) of 13.75% if the stock gets called away at the August 2024 expiration (before broker commissions). Of course, a lot of upside could potentially be left on the table if A shares really soar, which is why looking at the trailing twelve month trading history for Agilent Technologies, Inc., as well as studying the business fundamentals becomes important. Below is a chart showing A's trailing twelve month trading history, with the $150.00 strike highlighted in red:\n",
      "Considering the fact that the $150.00 strike represents an approximate 8% premium to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the covered call contract would expire worthless, in which case the investor would keep both their shares of stock and the premium collected. The current analytical data (including greeks and implied greeks) suggest the current odds of that happening are 53%. On our website under the contract detail page for this contract, Stock Options Channel will track those odds over time to see how they change and publish a chart of those numbers (the trading history of the option contract will also be charted). Should the covered call contract expire worthless, the premium would represent a 5.83% boost of extra return to the investor, or 8.83% annualized, which we refer to as the YieldBoost.\n",
      "The implied volatility in the put contract example is 32%, while the implied volatility in the call contract example is 29%.\n",
      "Meanwhile, we calculate the actual trailing twelve month volatility (considering the last 251 trading day closing values as well as today's price of $138.99) to be 27%. For more put and call options contract ideas worth looking at, visit StockOptionsChannel.com.\n",
      "Top YieldBoost Calls of Stocks Analysts Like »\n",
      "Also see:\n",
      " Canadian Stocks Crossing Below Their 200 Day Moving Avg\n",
      " Funds Holding SNUG\n",
      " CCE Insider Buying\n",
      "The views and opinions expressed herein are the views and opinions of the author and do not necessarily reflect those of Nasdaq, Inc.\n",
      "Lsa_summary: Because the $125.00 strike represents an approximate 10% discount to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the put contract would expire worthless. Of course, a lot of upside could potentially be left on the table if A shares really soar, which is why looking at the trailing twelve month trading history for Agilent Technologies, Inc., as well as studying the business fundamentals becomes important. Below is a chart showing A's trailing twelve month trading history, with the $150.00 strike highlighted in red: Considering the fact that the $150.00 strike represents an approximate 8% premium to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the covered call contract would expire worthless, in which case the investor would keep both their shares of stock and the premium collected.\n",
      "Luhn_summary: The current analytical data (including greeks and implied greeks) suggest the current odds of that happening are 77%. Below is a chart showing the trailing twelve month trading history for Agilent Technologies, Inc., and highlighting in green where the $125.00 strike is located relative to that history: Turning to the calls side of the option chain, the call contract at the $150.00 strike price has a current bid of $8.10. The current analytical data (including greeks and implied greeks) suggest the current odds of that happening are 53%.\n",
      "Textrank_summary: Below is a chart showing the trailing twelve month trading history for Agilent Technologies, Inc., and highlighting in green where the $125.00 strike is located relative to that history: Turning to the calls side of the option chain, the call contract at the $150.00 strike price has a current bid of $8.10. Below is a chart showing A's trailing twelve month trading history, with the $150.00 strike highlighted in red: Considering the fact that the $150.00 strike represents an approximate 8% premium to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the covered call contract would expire worthless, in which case the investor would keep both their shares of stock and the premium collected. On our website under the contract detail page for this contract, Stock Options Channel will track those odds over time to see how they change and publish a chart of those numbers (the trading history of the option contract will also be charted).\n",
      "Lexrank_summary: At Stock Options Channel, our YieldBoost formula has looked up and down the A options chain for the new August 2024 contracts and identified one put and one call contract of particular interest. Should the contract expire worthless, the premium would represent a 3.60% return on the cash commitment, or 5.45% annualized — at Stock Options Channel we call this the YieldBoost. Below is a chart showing A's trailing twelve month trading history, with the $150.00 strike highlighted in red: Considering the fact that the $150.00 strike represents an approximate 8% premium to the current trading price of the stock (in other words it is out-of-the-money by that percentage), there is also the possibility that the covered call contract would expire worthless, in which case the investor would keep both their shares of stock and the premium collected.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take first row to test\n",
    "row = news_df.iloc[0]\n",
    "\n",
    "# Create the input text by concatenating the columns with their names and values\n",
    "input_text = \"\"\n",
    "for col in news_df.columns:\n",
    "    # Skip the columns that are not needed for the input text\n",
    "    if not col in [\"Date\", \"Stock_symbol\"]:\n",
    "        input_text += f\"{col}: {row[col]}\\n\"\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0493a3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 3720, 1035,  ..., 5067, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]])}\n",
      "1711\n"
     ]
    }
   ],
   "source": [
    "input_tokenized = tokenizer(input_text, return_tensors=\"pt\")\n",
    "print(input_tokenized)\n",
    "print(len(input_tokenized[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61222471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import torch\n",
    "\n",
    "sentiments = []\n",
    "\n",
    "for i in range(ceil(len(input_tokenized[\"input_ids\"][0]) / 512)):\n",
    "    # Get the start and end indices for the current chunk\n",
    "    start = i * 512\n",
    "    end = min((i + 1) * 512, len(input_tokenized[\"input_ids\"][0]))\n",
    "\n",
    "    # Get the input IDs for the current chunk\n",
    "    input_ids_chunk = input_tokenized[\"input_ids\"][0][start:end].unsqueeze(0)\n",
    "\n",
    "    # Get the attention mask for the current chunk\n",
    "    attention_mask_chunk = input_tokenized[\"attention_mask\"][0][start:end].unsqueeze(0)\n",
    "\n",
    "    # Get the model output for the current chunk\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids_chunk, attention_mask=attention_mask_chunk)\n",
    "        logits = output.logits\n",
    "\n",
    "    # Get the predicted sentiment for the current chunk\n",
    "    sentiment = logits[0]\n",
    "    # Append sentiment value and the length of the chunk that will be used as a weight for the average to the sentiments list\n",
    "    sentiments.append((sentiment, end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68060fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([-0.4522, -1.1169,  2.0375]), 512), (tensor([-0.5175, -1.2336,  2.1715]), 512), (tensor([-0.3820, -1.3655,  1.9722]), 512), (tensor([-0.7449, -1.1740,  2.2532]), 175)]\n"
     ]
    }
   ],
   "source": [
    "print(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62f5e78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4807, -1.2320,  2.0801])\n"
     ]
    }
   ],
   "source": [
    "# Average the sentiments using the weights\n",
    "weighted_sentiment = sum([sentiment[0] * sentiment[1] for sentiment in sentiments]) / sum([sentiment[1] for sentiment in sentiments])\n",
    "print(weighted_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb5e0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4000000059604645\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    torch.tensor([0.1, 0.2, 0.3]),\n",
    "    torch.tensor([0.4, 0.5, 0.6]),\n",
    "    torch.tensor([0.7, 0.8, 0.9])\n",
    "]\n",
    "\n",
    "# Average the tensors\n",
    "average_tensor = sum(test) / len(test)\n",
    "print(average_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc2d817",
   "metadata": {},
   "source": [
    "# Sentiment processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b7ea1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def compute_sentiment_for_stock(stock_df, stock_symbol, date):\n",
    "    news_for_stock = get_news_for_stock(stock_symbol, date)\n",
    "\n",
    "    # Add the number of news found to the stock DataFrame\n",
    "    stock_df.at[index, \"News_count\"] = len(news_for_stock)\n",
    "\n",
    "    # If there are no news articles for the stock on that date, set the sentiment to 0\n",
    "    sentiments = [0] * 3\n",
    "\n",
    "    print(f\"Computing sentiment for {len(news_for_stock)} news articles\")\n",
    "    if len(news_for_stock) > 0:\n",
    "        sentiments = []\n",
    "        for _, row in news_for_stock.iterrows():\n",
    "            sentiment = compute_sentiment(row)\n",
    "            sentiments.append(sentiment)\n",
    "\n",
    "        # Average the sentiments\n",
    "        sentiments = sum(sentiments) / len(sentiments)\n",
    "        sentiments = [np.float64(tensor.item()) for tensor in sentiments]\n",
    "    \n",
    "    print(\"Adding sentiment to stock DataFrame\")\n",
    "    # Add the average sentiment to the stock DataFrame\n",
    "    for i in range(len(sentiments)):\n",
    "        stock_df.at[index, f\"Sentiment_{i}\"] = sentiments[i]\n",
    "\n",
    "\n",
    "def compute_sentiment(row):\n",
    "    input_tokenized = tokenize_input(row)\n",
    "    sentiments = []\n",
    "\n",
    "    for i in range(ceil(len(input_tokenized[\"input_ids\"][0]) / 512)):\n",
    "        # Get the start and end indices for the current chunk\n",
    "        start = i * 512\n",
    "        end = min((i + 1) * 512, len(input_tokenized[\"input_ids\"][0]))\n",
    "\n",
    "        # Get the input IDs for the current chunk\n",
    "        input_ids_chunk = input_tokenized[\"input_ids\"][0][start:end].unsqueeze(0)\n",
    "\n",
    "        # Get the attention mask for the current chunk\n",
    "        attention_mask_chunk = input_tokenized[\"attention_mask\"][0][start:end].unsqueeze(0)\n",
    "\n",
    "        # Get the model output for the current chunk\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids_chunk, attention_mask=attention_mask_chunk)\n",
    "            logits = output.logits\n",
    "\n",
    "        # Get the predicted sentiment for the current chunk\n",
    "        sentiment = logits[0]\n",
    "        # Append sentiment value and the length of the chunk that will be used as a weight for the average to the sentiments list\n",
    "        sentiments.append((sentiment, end - start))\n",
    "\n",
    "    # Average the sentiments using the weights\n",
    "    weighted_sentiment = sum([sentiment[0] * sentiment[1] for sentiment in sentiments]) / sum([sentiment[1] for sentiment in sentiments])\n",
    "    return weighted_sentiment\n",
    "\n",
    "def tokenize_input(row):\n",
    "    # Create the input text by concatenating the columns with their names and values\n",
    "    input_text = \"\"\n",
    "    for col in news_df.columns:\n",
    "        # Skip the columns that are not needed for the input text\n",
    "        if not col in [\"Date\", \"Stock_symbol\"]:\n",
    "            input_text += f\"{col}: {row[col]}\\n\"\n",
    "\n",
    "    return tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "def get_stock_files():\n",
    "    # Get the list of all stock csv files in the directory\n",
    "    stock_files = [\"../data/normalized/sp500/csv/\" + f for f in os.listdir(\"../data/normalized/sp500/csv\") if f.endswith(\".csv\")]\n",
    "    # Remove the .DS_Store file if it exists\n",
    "    if \".DS_Store\" in stock_files:\n",
    "        stock_files.remove(\".DS_Store\")\n",
    "    return stock_files\n",
    "\n",
    "def get_news_for_stock(stock_symbol, date):\n",
    "    # Filter the news DataFrame to get the rows that match the stock symbol and date\n",
    "    news_for_stock = news_df[(news_df[\"Stock_symbol\"] == stock_symbol) & (news_df[\"Date\"] == date)]\n",
    "\n",
    "    return news_for_stock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada295d",
   "metadata": {},
   "source": [
    "* For each stock csv file\n",
    "    * For each entry\n",
    "        * Find the news from news_df with the same date and stock symbol\n",
    "        * Compute the sentiment of all the news\n",
    "        * Average the sentiment of all the news\n",
    "        * Add to the stock csv files 3 columns (1 for each sentiment component)\n",
    "        * Add to the stock csv files a column that contains the number of news found for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8dade178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../data/normalized/sp500/csv/A.csv', '../data/normalized/sp500/csv/AAL.csv', '../data/normalized/sp500/csv/AAP.csv', '../data/normalized/sp500/csv/AAPL.csv', '../data/normalized/sp500/csv/ABC.csv', '../data/normalized/sp500/csv/ABMD.csv', '../data/normalized/sp500/csv/ABT.csv', '../data/normalized/sp500/csv/ACN.csv', '../data/normalized/sp500/csv/ADI.csv', '../data/normalized/sp500/csv/ADM.csv', '../data/normalized/sp500/csv/ADP.csv', '../data/normalized/sp500/csv/ADSK.csv', '../data/normalized/sp500/csv/AEE.csv', '../data/normalized/sp500/csv/AEP.csv', '../data/normalized/sp500/csv/AIZ.csv', '../data/normalized/sp500/csv/AJG.csv', '../data/normalized/sp500/csv/AKAM.csv', '../data/normalized/sp500/csv/ALB.csv', '../data/normalized/sp500/csv/ALGN.csv', '../data/normalized/sp500/csv/ALK.csv', '../data/normalized/sp500/csv/AMAT.csv', '../data/normalized/sp500/csv/AMD.csv', '../data/normalized/sp500/csv/AME.csv', '../data/normalized/sp500/csv/AMGN.csv', '../data/normalized/sp500/csv/AMP.csv', '../data/normalized/sp500/csv/AMT.csv', '../data/normalized/sp500/csv/AMZN.csv', '../data/normalized/sp500/csv/AON.csv', '../data/normalized/sp500/csv/AOS.csv', '../data/normalized/sp500/csv/APA.csv', '../data/normalized/sp500/csv/APD.csv', '../data/normalized/sp500/csv/APH.csv', '../data/normalized/sp500/csv/ARE.csv', '../data/normalized/sp500/csv/ATVI.csv', '../data/normalized/sp500/csv/AVB.csv', '../data/normalized/sp500/csv/AVY.csv', '../data/normalized/sp500/csv/AXP.csv', '../data/normalized/sp500/csv/AZO.csv', '../data/normalized/sp500/csv/BA.csv', '../data/normalized/sp500/csv/BAC.csv', '../data/normalized/sp500/csv/BAX.csv', '../data/normalized/sp500/csv/BBY.csv', '../data/normalized/sp500/csv/BDX.csv', '../data/normalized/sp500/csv/BEN.csv', '../data/normalized/sp500/csv/BF-A.csv', '../data/normalized/sp500/csv/BIIB.csv', '../data/normalized/sp500/csv/BIO.csv', '../data/normalized/sp500/csv/BK.csv', '../data/normalized/sp500/csv/BLK.csv', '../data/normalized/sp500/csv/BMRA.csv', '../data/normalized/sp500/csv/BMY.csv', '../data/normalized/sp500/csv/BR.csv', '../data/normalized/sp500/csv/BRK-A.csv', '../data/normalized/sp500/csv/BSX.csv', '../data/normalized/sp500/csv/BWA.csv', '../data/normalized/sp500/csv/BXP.csv', '../data/normalized/sp500/csv/C.csv', '../data/normalized/sp500/csv/CAG.csv', '../data/normalized/sp500/csv/CAH.csv', '../data/normalized/sp500/csv/CAT.csv', '../data/normalized/sp500/csv/CB.csv', '../data/normalized/sp500/csv/CCI.csv', '../data/normalized/sp500/csv/CDE.csv', '../data/normalized/sp500/csv/CDNS.csv', '../data/normalized/sp500/csv/CF.csv', '../data/normalized/sp500/csv/CHD.csv', '../data/normalized/sp500/csv/CHRW.csv', '../data/normalized/sp500/csv/CINF.csv', '../data/normalized/sp500/csv/CL.csv', '../data/normalized/sp500/csv/CLX.csv', '../data/normalized/sp500/csv/CME.csv', '../data/normalized/sp500/csv/CMG.csv', '../data/normalized/sp500/csv/CMI.csv', '../data/normalized/sp500/csv/CNC.csv', '../data/normalized/sp500/csv/CNP.csv', '../data/normalized/sp500/csv/COO.csv', '../data/normalized/sp500/csv/COP.csv', '../data/normalized/sp500/csv/COST.csv', '../data/normalized/sp500/csv/COWN.csv', '../data/normalized/sp500/csv/CPB.csv', '../data/normalized/sp500/csv/CPRT.csv', '../data/normalized/sp500/csv/CRM.csv', '../data/normalized/sp500/csv/CSCO.csv', '../data/normalized/sp500/csv/CTAS.csv', '../data/normalized/sp500/csv/CTSH.csv', '../data/normalized/sp500/csv/CUK.csv', '../data/normalized/sp500/csv/D.csv', '../data/normalized/sp500/csv/DAL.csv', '../data/normalized/sp500/csv/DE.csv', '../data/normalized/sp500/csv/DFS.csv', '../data/normalized/sp500/csv/DGX.csv', '../data/normalized/sp500/csv/DHI.csv', '../data/normalized/sp500/csv/DIS.csv', '../data/normalized/sp500/csv/DLTR.csv', '../data/normalized/sp500/csv/DOV.csv', '../data/normalized/sp500/csv/DPZ.csv', '../data/normalized/sp500/csv/DRI.csv', '../data/normalized/sp500/csv/DTE.csv', '../data/normalized/sp500/csv/DVA.csv', '../data/normalized/sp500/csv/DXCM.csv', '../data/normalized/sp500/csv/EA.csv', '../data/normalized/sp500/csv/EBAY.csv', '../data/normalized/sp500/csv/ECL.csv', '../data/normalized/sp500/csv/ED.csv', '../data/normalized/sp500/csv/EFX.csv', '../data/normalized/sp500/csv/EIX.csv', '../data/normalized/sp500/csv/EL.csv', '../data/normalized/sp500/csv/EMN.csv', '../data/normalized/sp500/csv/EMR.csv', '../data/normalized/sp500/csv/ENS.csv', '../data/normalized/sp500/csv/EOG.csv', '../data/normalized/sp500/csv/EQIX.csv', '../data/normalized/sp500/csv/EQR.csv', '../data/normalized/sp500/csv/ES.csv', '../data/normalized/sp500/csv/ESS.csv', '../data/normalized/sp500/csv/EW.csv', '../data/normalized/sp500/csv/EXR.csv', '../data/normalized/sp500/csv/F.csv', '../data/normalized/sp500/csv/FAST.csv', '../data/normalized/sp500/csv/FCX.csv', '../data/normalized/sp500/csv/FDX.csv', '../data/normalized/sp500/csv/FE.csv', '../data/normalized/sp500/csv/FFIV.csv', '../data/normalized/sp500/csv/FIS.csv', '../data/normalized/sp500/csv/FISV.csv', '../data/normalized/sp500/csv/FITB.csv', '../data/normalized/sp500/csv/FLS.csv', '../data/normalized/sp500/csv/FMC.csv', '../data/normalized/sp500/csv/FRT.csv', '../data/normalized/sp500/csv/FTI.csv', '../data/normalized/sp500/csv/GD.csv', '../data/normalized/sp500/csv/GE.csv', '../data/normalized/sp500/csv/GGG.csv', '../data/normalized/sp500/csv/GILD.csv', '../data/normalized/sp500/csv/GIS.csv', '../data/normalized/sp500/csv/GOOG.csv', '../data/normalized/sp500/csv/GPC.csv', '../data/normalized/sp500/csv/GPN.csv', '../data/normalized/sp500/csv/GRMN.csv', '../data/normalized/sp500/csv/GWW.csv', '../data/normalized/sp500/csv/HAL.csv', '../data/normalized/sp500/csv/HAS.csv', '../data/normalized/sp500/csv/HBAN.csv', '../data/normalized/sp500/csv/HBI.csv', '../data/normalized/sp500/csv/HD.csv', '../data/normalized/sp500/csv/HES.csv', '../data/normalized/sp500/csv/HOLX.csv', '../data/normalized/sp500/csv/HON.csv', '../data/normalized/sp500/csv/HPQ.csv', '../data/normalized/sp500/csv/HRB.csv', '../data/normalized/sp500/csv/HRL.csv', '../data/normalized/sp500/csv/HSIC.csv', '../data/normalized/sp500/csv/HST.csv', '../data/normalized/sp500/csv/HSY.csv', '../data/normalized/sp500/csv/HTLF.csv', '../data/normalized/sp500/csv/HUM.csv', '../data/normalized/sp500/csv/IBM.csv', '../data/normalized/sp500/csv/ICE.csv', '../data/normalized/sp500/csv/IDXX.csv', '../data/normalized/sp500/csv/IEX.csv', '../data/normalized/sp500/csv/IFF.csv', '../data/normalized/sp500/csv/ILMN.csv', '../data/normalized/sp500/csv/INTU.csv', '../data/normalized/sp500/csv/IP.csv', '../data/normalized/sp500/csv/IPGP.csv', '../data/normalized/sp500/csv/IRM.csv', '../data/normalized/sp500/csv/ISRG.csv', '../data/normalized/sp500/csv/IT.csv', '../data/normalized/sp500/csv/ITW.csv', '../data/normalized/sp500/csv/IVZ.csv', '../data/normalized/sp500/csv/JBHT.csv', '../data/normalized/sp500/csv/JCI.csv', '../data/normalized/sp500/csv/JKHY.csv', '../data/normalized/sp500/csv/JNJ.csv', '../data/normalized/sp500/csv/JNPR.csv', '../data/normalized/sp500/csv/JPM.csv', '../data/normalized/sp500/csv/K.csv', '../data/normalized/sp500/csv/KEY.csv', '../data/normalized/sp500/csv/KIM.csv', '../data/normalized/sp500/csv/KMB.csv', '../data/normalized/sp500/csv/KMX.csv', '../data/normalized/sp500/csv/KO.csv', '../data/normalized/sp500/csv/KR.csv', '../data/normalized/sp500/csv/KSS.csv', '../data/normalized/sp500/csv/LBTYA.csv', '../data/normalized/sp500/csv/LDOS.csv', '../data/normalized/sp500/csv/LEG.csv', '../data/normalized/sp500/csv/LH.csv', '../data/normalized/sp500/csv/LKQ.csv', '../data/normalized/sp500/csv/LMT.csv', '../data/normalized/sp500/csv/LNC.csv', '../data/normalized/sp500/csv/LNT.csv', '../data/normalized/sp500/csv/LOW.csv', '../data/normalized/sp500/csv/LRCX.csv', '../data/normalized/sp500/csv/LUV.csv', '../data/normalized/sp500/csv/LVS.csv', '../data/normalized/sp500/csv/LYV.csv', '../data/normalized/sp500/csv/MAA.csv', '../data/normalized/sp500/csv/MAR.csv', '../data/normalized/sp500/csv/MCD.csv', '../data/normalized/sp500/csv/MCHP.csv', '../data/normalized/sp500/csv/MCK.csv', '../data/normalized/sp500/csv/MCO.csv', '../data/normalized/sp500/csv/MDLZ.csv', '../data/normalized/sp500/csv/MDT.csv', '../data/normalized/sp500/csv/MET.csv', '../data/normalized/sp500/csv/MGM.csv', '../data/normalized/sp500/csv/MHK.csv', '../data/normalized/sp500/csv/MKTX.csv', '../data/normalized/sp500/csv/MLM.csv', '../data/normalized/sp500/csv/MMC.csv', '../data/normalized/sp500/csv/MMM.csv', '../data/normalized/sp500/csv/MNST.csv', '../data/normalized/sp500/csv/MO.csv', '../data/normalized/sp500/csv/MOS.csv', '../data/normalized/sp500/csv/MRK.csv', '../data/normalized/sp500/csv/MRO.csv', '../data/normalized/sp500/csv/MSFT.csv', '../data/normalized/sp500/csv/MSI.csv', '../data/normalized/sp500/csv/MU.csv', '../data/normalized/sp500/csv/NDAQ.csv', '../data/normalized/sp500/csv/NEE.csv', '../data/normalized/sp500/csv/NEOG.csv', '../data/normalized/sp500/csv/NFLX.csv', '../data/normalized/sp500/csv/NI.csv', '../data/normalized/sp500/csv/NOC.csv', '../data/normalized/sp500/csv/NOK.csv', '../data/normalized/sp500/csv/NOV.csv', '../data/normalized/sp500/csv/NRG.csv', '../data/normalized/sp500/csv/NSC.csv', '../data/normalized/sp500/csv/NTAP.csv', '../data/normalized/sp500/csv/NTRS.csv', '../data/normalized/sp500/csv/NVR.csv', '../data/normalized/sp500/csv/NWL.csv', '../data/normalized/sp500/csv/O.csv', '../data/normalized/sp500/csv/ODFL.csv', '../data/normalized/sp500/csv/OKE.csv', '../data/normalized/sp500/csv/OMC.csv', '../data/normalized/sp500/csv/ORLY.csv', '../data/normalized/sp500/csv/OXY.csv', '../data/normalized/sp500/csv/PAYX.csv', '../data/normalized/sp500/csv/PCAR.csv', '../data/normalized/sp500/csv/PEG.csv', '../data/normalized/sp500/csv/PEP.csv', '../data/normalized/sp500/csv/PFE.csv', '../data/normalized/sp500/csv/PG.csv', '../data/normalized/sp500/csv/PH.csv', '../data/normalized/sp500/csv/PHM.csv', '../data/normalized/sp500/csv/PKG.csv', '../data/normalized/sp500/csv/PKI.csv', '../data/normalized/sp500/csv/PLD.csv', '../data/normalized/sp500/csv/PNR.csv', '../data/normalized/sp500/csv/PNW.csv', '../data/normalized/sp500/csv/PPG.csv', '../data/normalized/sp500/csv/PRU.csv', '../data/normalized/sp500/csv/PVH.csv', '../data/normalized/sp500/csv/PWR.csv', '../data/normalized/sp500/csv/PXD.csv', '../data/normalized/sp500/csv/RCL.csv', '../data/normalized/sp500/csv/RE.csv', '../data/normalized/sp500/csv/REG.csv', '../data/normalized/sp500/csv/REGN.csv', '../data/normalized/sp500/csv/RF.csv', '../data/normalized/sp500/csv/RHI.csv', '../data/normalized/sp500/csv/RIBT.csv', '../data/normalized/sp500/csv/RJF.csv', '../data/normalized/sp500/csv/RL.csv', '../data/normalized/sp500/csv/RLI.csv', '../data/normalized/sp500/csv/RMD.csv', '../data/normalized/sp500/csv/ROK.csv', '../data/normalized/sp500/csv/ROL.csv', '../data/normalized/sp500/csv/ROP.csv', '../data/normalized/sp500/csv/ROST.csv', '../data/normalized/sp500/csv/RSG.csv', '../data/normalized/sp500/csv/SBUX.csv', '../data/normalized/sp500/csv/SCHW.csv', '../data/normalized/sp500/csv/SEE.csv', '../data/normalized/sp500/csv/SEGXF.csv', '../data/normalized/sp500/csv/SHW.csv', '../data/normalized/sp500/csv/SIVB.csv', '../data/normalized/sp500/csv/SLB.csv', '../data/normalized/sp500/csv/SLG.csv', '../data/normalized/sp500/csv/SNPS.csv', '../data/normalized/sp500/csv/SO.csv', '../data/normalized/sp500/csv/SPG.csv', '../data/normalized/sp500/csv/SRE.csv', '../data/normalized/sp500/csv/STT.csv', '../data/normalized/sp500/csv/STX.csv', '../data/normalized/sp500/csv/SWK.csv', '../data/normalized/sp500/csv/SWKS.csv', '../data/normalized/sp500/csv/SYK.csv', '../data/normalized/sp500/csv/T.csv', '../data/normalized/sp500/csv/TAP.csv', '../data/normalized/sp500/csv/TEL.csv', '../data/normalized/sp500/csv/TJX.csv', '../data/normalized/sp500/csv/TMO.csv', '../data/normalized/sp500/csv/TMUS.csv', '../data/normalized/sp500/csv/TROW.csv', '../data/normalized/sp500/csv/TRV.csv', '../data/normalized/sp500/csv/TSCO.csv', '../data/normalized/sp500/csv/TSN.csv', '../data/normalized/sp500/csv/TTWO.csv', '../data/normalized/sp500/csv/TXN.csv', '../data/normalized/sp500/csv/TXT.csv', '../data/normalized/sp500/csv/TYL.csv', '../data/normalized/sp500/csv/UAL.csv', '../data/normalized/sp500/csv/UDR.csv', '../data/normalized/sp500/csv/UEEC.csv', '../data/normalized/sp500/csv/UHS.csv', '../data/normalized/sp500/csv/UNM.csv', '../data/normalized/sp500/csv/UNP.csv', '../data/normalized/sp500/csv/UPS.csv', '../data/normalized/sp500/csv/URI.csv', '../data/normalized/sp500/csv/USB.csv', '../data/normalized/sp500/csv/VFC.csv', '../data/normalized/sp500/csv/VMC.csv', '../data/normalized/sp500/csv/VRSN.csv', '../data/normalized/sp500/csv/VTR.csv', '../data/normalized/sp500/csv/VZ.csv', '../data/normalized/sp500/csv/WAT.csv', '../data/normalized/sp500/csv/WBA.csv', '../data/normalized/sp500/csv/WDC.csv', '../data/normalized/sp500/csv/WEC.csv', '../data/normalized/sp500/csv/WHR.csv', '../data/normalized/sp500/csv/WM.csv', '../data/normalized/sp500/csv/WMB.csv', '../data/normalized/sp500/csv/WRB.csv', '../data/normalized/sp500/csv/WST.csv', '../data/normalized/sp500/csv/WU.csv', '../data/normalized/sp500/csv/WY.csv', '../data/normalized/sp500/csv/WYNN.csv', '../data/normalized/sp500/csv/XEL.csv', '../data/normalized/sp500/csv/XOM.csv', '../data/normalized/sp500/csv/YUM.csv', '../data/normalized/sp500/csv/ZBH.csv', '../data/normalized/sp500/csv/ZION.csv']\n"
     ]
    }
   ],
   "source": [
    "stock_files = get_stock_files()\n",
    "print(stock_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d9ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ../data/normalized/sp500/csv/A.csv\n",
      "Getting news for date: 2008-01-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-04\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-07\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-08\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-10\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-14\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-15\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-16\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-18\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-22\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-25\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-28\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-29\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-30\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-01-31\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-01\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-04\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-05\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-06\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-07\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-08\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-12\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-13\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-14\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-15\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-19\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-20\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-21\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-22\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-25\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-26\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-27\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-28\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-02-29\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-04\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-05\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-06\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-07\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-10\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-12\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-13\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-14\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-18\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-19\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-20\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-25\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-26\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-27\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-28\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-03-31\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-01\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-04\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-07\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-08\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-10\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-14\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-15\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-16\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-18\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-21\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-22\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-25\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-28\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-29\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-04-30\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-01\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-05\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-06\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-07\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-08\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-12\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-13\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-14\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-15\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-16\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-19\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-20\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-21\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-22\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-27\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-28\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-29\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-05-30\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-04\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-05\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-06\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-10\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-12\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-13\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-16\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-18\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-19\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-20\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-25\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-26\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-27\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-06-30\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-01\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-07\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-08\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-10\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-14\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-15\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-16\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-18\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-21\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-22\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-25\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-28\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-29\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-30\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-07-31\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-01\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-04\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-05\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-06\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-07\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-08\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-12\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-13\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-14\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-15\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-18\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-19\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-20\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-21\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-22\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-25\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-26\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-27\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-28\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-08-29\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-04\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-05\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-08\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-10\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-12\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-15\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-16\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-18\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-19\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-22\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-25\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-26\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-29\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-09-30\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-01\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-06\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-07\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-08\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-10\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-13\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-14\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-15\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-16\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-20\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-21\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-22\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-27\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-28\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-29\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-30\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-10-31\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-04\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-05\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-06\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-07\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-10\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-12\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-13\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-14\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-18\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-19\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-20\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-21\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-25\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-26\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-11-28\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-01\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-04\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-05\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-08\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-10\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-12\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-15\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-16\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-18\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-19\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-22\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-26\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-29\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-30\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2008-12-31\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-05\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-06\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-07\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-08\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-12\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-13\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-14\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-15\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-16\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-20\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-21\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-22\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-26\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-27\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-28\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-29\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-01-30\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-04\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-05\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-06\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-10\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-12\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-13\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-18\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-19\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-20\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-25\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-26\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-02-27\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-04\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-05\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-06\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-10\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-11\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-12\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-13\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-16\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-18\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-19\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-20\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-25\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-26\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-27\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-30\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-03-31\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-01\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-02\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-03\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-06\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-07\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-08\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-09\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-13\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-14\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-15\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-16\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-17\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-20\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-21\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-22\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-23\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-24\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-27\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-28\n",
      "Computing sentiment for 0 news articles\n",
      "Adding sentiment to stock DataFrame\n",
      "Getting news for date: 2009-04-29\n",
      "Computing sentiment for 1 news articles\n",
      "Adding sentiment to stock DataFrame\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'torch.dtype' object has no attribute 'kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[100]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Add the average sentiment to the stock DataFrame\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sentiments)):\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m         \u001b[43mstock_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSentiment_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m = sentiments[i]\n\u001b[32m     40\u001b[39m stock_df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\crmgr\\anaconda3\\envs\\master_gcc\\Lib\\site-packages\\pandas\\core\\indexing.py:2586\u001b[39m, in \u001b[36m_AtIndexer.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   2583\u001b[39m     \u001b[38;5;28mself\u001b[39m.obj.loc[key] = value\n\u001b[32m   2584\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2586\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\crmgr\\anaconda3\\envs\\master_gcc\\Lib\\site-packages\\pandas\\core\\indexing.py:2542\u001b[39m, in \u001b[36m_ScalarAccessIndexer.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m   2539\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) != \u001b[38;5;28mself\u001b[39m.ndim:\n\u001b[32m   2540\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNot enough indexers for scalar access (setting)!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2542\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_set_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\crmgr\\anaconda3\\envs\\master_gcc\\Lib\\site-packages\\pandas\\core\\frame.py:4563\u001b[39m, in \u001b[36mDataFrame._set_value\u001b[39m\u001b[34m(self, index, col, value, takeable)\u001b[39m\n\u001b[32m   4561\u001b[39m         icol = \u001b[38;5;28mself\u001b[39m.columns.get_loc(col)\n\u001b[32m   4562\u001b[39m         iindex = \u001b[38;5;28mself\u001b[39m.index.get_loc(index)\n\u001b[32m-> \u001b[39m\u001b[32m4563\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumn_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43micol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   4564\u001b[39m     \u001b[38;5;28mself\u001b[39m._clear_item_cache()\n\u001b[32m   4566\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, LossySetitemError):\n\u001b[32m   4567\u001b[39m     \u001b[38;5;66;03m# get_loc might raise a KeyError for missing labels (falling back\u001b[39;00m\n\u001b[32m   4568\u001b[39m     \u001b[38;5;66;03m#  to (i)loc will do expansion of the index)\u001b[39;00m\n\u001b[32m   4569\u001b[39m     \u001b[38;5;66;03m# column_setitem will do validation that may raise TypeError,\u001b[39;00m\n\u001b[32m   4570\u001b[39m     \u001b[38;5;66;03m#  ValueError, or LossySetitemError\u001b[39;00m\n\u001b[32m   4571\u001b[39m     \u001b[38;5;66;03m# set using a non-recursive method & reset the cache\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\crmgr\\anaconda3\\envs\\master_gcc\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1335\u001b[39m, in \u001b[36mBlockManager.column_setitem\u001b[39m\u001b[34m(self, loc, idx, value, inplace_only)\u001b[39m\n\u001b[32m   1333\u001b[39m col_mgr = \u001b[38;5;28mself\u001b[39m.iget(loc, track_ref=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace_only:\n\u001b[32m-> \u001b[39m\u001b[32m1335\u001b[39m     \u001b[43mcol_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetitem_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1337\u001b[39m     new_mgr = col_mgr.setitem((idx,), value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\crmgr\\anaconda3\\envs\\master_gcc\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2044\u001b[39m, in \u001b[36mSingleBlockManager.setitem_inplace\u001b[39m\u001b[34m(self, indexer, value, warn)\u001b[39m\n\u001b[32m   2037\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m warn_cow \u001b[38;5;129;01mand\u001b[39;00m warn:\n\u001b[32m   2038\u001b[39m         warnings.warn(\n\u001b[32m   2039\u001b[39m             COW_WARNING_SETITEM_MSG,\n\u001b[32m   2040\u001b[39m             \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m   2041\u001b[39m             stacklevel=find_stack_level(),\n\u001b[32m   2042\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m2044\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetitem_inplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\crmgr\\anaconda3\\envs\\master_gcc\\Lib\\site-packages\\pandas\\core\\internals\\base.py:357\u001b[39m, in \u001b[36mSingleDataManager.setitem_inplace\u001b[39m\u001b[34m(self, indexer, value, warn)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# EAs will do this validation in their own __setitem__ methods.\u001b[39;00m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, np.ndarray):\n\u001b[32m    355\u001b[39m     \u001b[38;5;66;03m# Note: checking for ndarray instead of np.dtype means we exclude\u001b[39;00m\n\u001b[32m    356\u001b[39m     \u001b[38;5;66;03m#  dt64/td64, which do their own validation.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     value = \u001b[43mnp_can_hold_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np.ndarray) \u001b[38;5;129;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) == \u001b[32m1\u001b[39m:\n\u001b[32m    360\u001b[39m     \u001b[38;5;66;03m# NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\u001b[39;00m\n\u001b[32m    361\u001b[39m     value = value[\u001b[32m0\u001b[39m, ...]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\crmgr\\anaconda3\\envs\\master_gcc\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1868\u001b[39m, in \u001b[36mnp_can_hold_element\u001b[39m\u001b[34m(dtype, element)\u001b[39m\n\u001b[32m   1864\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LossySetitemError\n\u001b[32m   1866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tipo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1867\u001b[39m     \u001b[38;5;66;03m# TODO: itemsize check?\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1868\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtipo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkind\u001b[49m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miuf\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1869\u001b[39m         \u001b[38;5;66;03m# Anything other than float/integer we cannot hold\u001b[39;00m\n\u001b[32m   1870\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LossySetitemError\n\u001b[32m   1871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tipo, np.dtype):\n\u001b[32m   1872\u001b[39m         \u001b[38;5;66;03m# i.e. nullable IntegerDtype or FloatingDtype;\u001b[39;00m\n\u001b[32m   1873\u001b[39m         \u001b[38;5;66;03m#  we can put this into an ndarray losslessly iff it has no NAs\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'torch.dtype' object has no attribute 'kind'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "stock_files = get_stock_files()\n",
    "stock_files = stock_files[:1]\n",
    "\n",
    "for stock_file in stock_files:\n",
    "    print(f\"Processing file: {stock_file}\")\n",
    "\n",
    "    # Read the stock file\n",
    "    stock_df = pd.read_csv(stock_file)\n",
    "\n",
    "    stock_symbol = stock_df[\"Stock_symbol\"].iloc[0]\n",
    "\n",
    "    for index, row in stock_df.iterrows():\n",
    "        date = row[\"Date\"]\n",
    "\n",
    "        compute_sentiment_for_stock(stock_df, stock_symbol, date)\n",
    "        \n",
    "    stock_df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "548c896f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Stock_symbol</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "      <th>ABER_ZG_5_15</th>\n",
       "      <th>ABER_SG_5_15</th>\n",
       "      <th>...</th>\n",
       "      <th>VWMA_10</th>\n",
       "      <th>WCP</th>\n",
       "      <th>WILLR_14</th>\n",
       "      <th>WMA_10</th>\n",
       "      <th>ZL_EMA_10</th>\n",
       "      <th>ZS_30</th>\n",
       "      <th>News_count</th>\n",
       "      <th>Sentiment_0</th>\n",
       "      <th>Sentiment_1</th>\n",
       "      <th>Sentiment_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.130248</td>\n",
       "      <td>-1.131785</td>\n",
       "      <td>1.021779</td>\n",
       "      <td>-1.117936</td>\n",
       "      <td>-1.117422</td>\n",
       "      <td>-1.083444</td>\n",
       "      <td>-1.137467</td>\n",
       "      <td>-1.131569</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.138975</td>\n",
       "      <td>-1.12078</td>\n",
       "      <td>1.163775</td>\n",
       "      <td>-1.136809</td>\n",
       "      <td>-1.129139</td>\n",
       "      <td>1.460558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Stock_symbol       Low      Open    Volume      High  \\\n",
       "333  2009-04-29            A -1.130248 -1.131785  1.021779 -1.117936   \n",
       "\n",
       "        Close  Adjusted Close  ABER_ZG_5_15  ABER_SG_5_15  ...   VWMA_10  \\\n",
       "333 -1.117422       -1.083444     -1.137467     -1.131569  ... -1.138975   \n",
       "\n",
       "         WCP  WILLR_14    WMA_10  ZL_EMA_10     ZS_30  News_count  \\\n",
       "333 -1.12078  1.163775 -1.136809  -1.129139  1.460558         1.0   \n",
       "\n",
       "     Sentiment_0  Sentiment_1  Sentiment_2  \n",
       "333          NaN          NaN          NaN  \n",
       "\n",
       "[1 rows x 230 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df[stock_df[\"News_count\"] > 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8e9959ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stock_df[\"Low\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0a4ef70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5017825365066528, 0.2473420947790146, 2.3462471961975098]\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "news_for_stock = get_news_for_stock(\"A\", \"2009-04-29\")\n",
    "\n",
    "sentiments = [0] * 3\n",
    "if len(news_for_stock) > 0:\n",
    "    sentiments = []\n",
    "    for _, row in news_for_stock.iterrows():\n",
    "        sentiment = compute_sentiment(row)\n",
    "        sentiments.append(sentiment)\n",
    "\n",
    "    # Average the sentiments\n",
    "    sentiments = sum(sentiments) / len(sentiments)\n",
    "\n",
    "import numpy as np\n",
    "# convert tensor to numpy float64\n",
    "sentiments = [np.float64(tensor.item()) for tensor in sentiments]\n",
    "print(sentiments)\n",
    "print(type(sentiments[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec158d",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9500f6c",
   "metadata": {},
   "source": [
    "* Check FinBert input size\n",
    "* Decide how to pass the news info: (GCC mi dai un parere su questo?)\n",
    "    * Only the title as in the paper?\n",
    "    * Add also Author and summaries values?\n",
    "    * How to add them? Simple concatenation?\n",
    "    * Maybe doing sentiment on each independently and them averaging the sentiment results?\n",
    "* For each stock retrieve relative news for each date, compute sentiment and add score to the stock csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_gcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
