{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f9ca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2991408:MainThread](2025-05-31 15:02:42,886) INFO - qlib.Initialization - [config.py:420] - default_conf: client.\n",
      "[2991408:MainThread](2025-05-31 15:02:42,887) WARNING - qlib.Initialization - [__init__.py:64] - auto_path is False, please make sure None is mounted\n",
      "[2991408:MainThread](2025-05-31 15:02:43,334) INFO - qlib.Initialization - [__init__.py:74] - qlib successfully initialized based on client settings.\n",
      "[2991408:MainThread](2025-05-31 15:02:43,334) INFO - qlib.Initialization - [__init__.py:76] - data_path={'__DEFAULT_FREQ': PosixPath('/home/gabrielecarrino/.qlib/qlib_data/cn_data')}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  torch.Size([336, 3764, 227])\n"
     ]
    }
   ],
   "source": [
    "from master_bert import MASTERModel\n",
    "import pickle\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from utils import load_all_csv_data_with_market_indexes, load_all_csv_data_without_index, csvs_to_qlib_df, PandasDataLoader\n",
    "# Please install qlib first before load the data.\n",
    "\n",
    "# Qlib\n",
    "# import qlib\n",
    "# from qlib.config import REG_US           # S&P 500 is a US market\n",
    "# qlib.init(provider_uri=\".\", region=REG_US)   # provider_uri just needs to exist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1.  Init Qlib and build *one* handler\n",
    "import qlib, pandas as pd, numpy as np, torch\n",
    "qlib.init()                               # client mode is fine\n",
    "\n",
    "from qlib.data.dataset.loader import StaticDataLoader\n",
    "from qlib.data.dataset.handler import DataHandlerLP\n",
    "from qlib.data.dataset import TSDatasetH          # <-- here\n",
    "from qlib.data.dataset.processor import (\n",
    "    DropnaProcessor, CSZScoreNorm, DropnaLabel,\n",
    ")\n",
    "\n",
    "# your tensor, names, dates exactly as before  ----------------\n",
    "stock_tensor, stock_names, feature_names = load_all_csv_data_without_index()\n",
    "# stock_tensor, stock_names, feature_names = load_all_csv_data_with_market_indexes()\n",
    "N, T, K   = stock_tensor.shape\n",
    "print(\"Shape: \", stock_tensor.shape)\n",
    "# dates     = pd.read_csv(\"data/enriched/market_indexes_aggregated.csv\")[\"Date\"]\n",
    "# dates = pd.to_datetime(                     # <-- NEW\n",
    "#     pd.read_csv(\"data/enriched/market_indexes_aggregated.csv\")[\"Date\"]\n",
    "# )\n",
    "\n",
    "dates = pd.to_datetime(                     # <-- NEW\n",
    "    pd.read_csv(\"data/normalized/market_indexes_aggregated_normalized.csv\")[\"Date\"]\n",
    ")\n",
    "\n",
    "# tensor ➜ tidy multi-index frame --------------------------------\n",
    "def tensor_to_df(tensor, inst, feats, dt_index):\n",
    "    flat = tensor.numpy().reshape(N * T, K)\n",
    "    idx  = pd.MultiIndex.from_product([dt_index, inst],\n",
    "                                      names=[\"datetime\", \"instrument\"])\n",
    "    cols = pd.MultiIndex.from_product([[\"feature\"], feats])\n",
    "    return pd.DataFrame(flat, index=idx, columns=cols)\n",
    "\n",
    "df_raw = tensor_to_df(stock_tensor, stock_names, feature_names, dates)\n",
    "\n",
    "# # OLD: build a forward-return label\n",
    "# df_raw[(\"label\", \"FWD_RET\")] = (\n",
    "#     df_raw[(\"feature\", \"Adjusted Close\")]\n",
    "#       .groupby(\"instrument\").shift(-1) / df_raw[(\"feature\", \"Adjusted Close\")] - 1\n",
    "# )\n",
    "\n",
    "# last_date = dates.iloc[-1]\n",
    "# df_raw = df_raw.drop(index=last_date, level=\"datetime\")\n",
    "\n",
    "\n",
    "# MASTER uses a d-day rank-normalized return, which reflects each stock's relative performance within the market at a specific date\n",
    "# Steps: \n",
    "# Look Ahead:\n",
    "# For each stock, MASTER looks a few days into the future (like 5 days) to see how much the price goes up or down.\n",
    "\n",
    "# Calculate Return:\n",
    "# It calculates the percentage change in price over those days — this is the raw return.\n",
    "\n",
    "# Compare Stocks:\n",
    "# On each day, it compares the returns of all stocks to see which ones performed better or worse.\n",
    "\n",
    "# Z-score Normalization:\n",
    "# It transforms those returns into standard scores (z-scores), so you know how each stock ranks relative to the others that day.\n",
    "\n",
    "# Final Label:\n",
    "# The model learns to predict this ranked performance score, not just the raw return.\n",
    "\n",
    "# Oss: “The lookback window length T and prediction interval d are set as 8 and 5 respectively.” -- MaSTER paper\n",
    "\n",
    "# Step 1: Compute d-day forward return\n",
    "d = 5  # prediction interval\n",
    "df_raw[(\"label\", \"FWD_RET\")] = (\n",
    "    df_raw[(\"feature\", \"Adjusted Close\")]\n",
    "      .groupby(\"instrument\")\n",
    "      .shift(-d) / df_raw[(\"feature\", \"Adjusted Close\")] - 1\n",
    ")\n",
    "\n",
    "# Drop the last d rows since they can't have valid forward returns\n",
    "for i in range(d):\n",
    "    df_raw = df_raw.drop(index=dates.iloc[-(i+1)], level=\"datetime\")\n",
    "\n",
    "# Step 2: Z-score normalization across stocks (per date)\n",
    "df_raw[(\"label\", \"Z_RET\")] = (\n",
    "    df_raw[(\"label\", \"FWD_RET\")]\n",
    "    .groupby(\"datetime\")\n",
    "    .transform(lambda x: (x - x.mean()) / x.std())\n",
    ")\n",
    "\n",
    "df_raw = df_raw.drop(columns=[(\"label\", \"FWD_RET\")])\n",
    "\n",
    "# handler with learn / infer processors ------------------------\n",
    "proc_feat = [\n",
    "    {\"class\": \"DropnaProcessor\", \"kwargs\": {\"fields_group\": \"feature\"}},\n",
    "    # {\"class\": \"CSZScoreNorm\",   \"kwargs\": {\"fields_group\": \"feature\"}}, # slows down debugging\n",
    "]\n",
    "\n",
    "# proc_feat = [\n",
    "#     {\"class\": \"CSZScoreNorm\",   \"kwargs\": {\"fields_group\": \"feature\"}},\n",
    "# ]\n",
    "\n",
    "# proc_feat = [\n",
    "#     {\"class\": \"Fillna\",          # <— correct name\n",
    "#      \"kwargs\": {\"fields_group\": \"feature\", \"fill_value\": 0}},  # zero-fill; choose ffill/bfill/etc. if you like\n",
    "#     {\"class\": \"CSZScoreNorm\",\n",
    "#      \"kwargs\": {\"fields_group\": \"feature\"}},\n",
    "# ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696f648c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    datetime instrument   feature                                          \\\n",
      "                              Low      Open    Volume      High     Close   \n",
      "0 2008-01-02          A -0.754933 -0.751857 -0.368570 -0.759748 -0.762322   \n",
      "1 2008-01-02        AAL -0.761569 -0.761598 -0.283911 -0.771496 -0.771803   \n",
      "2 2008-01-02        AAP -0.792098 -0.780552  0.669788 -0.784548 -0.802615   \n",
      "3 2008-01-02       AAPL -0.783337 -0.786870  0.652856 -0.783765 -0.787604   \n",
      "4 2008-01-02        ABC -0.780683 -0.786344  0.998749 -0.787159 -0.788921   \n",
      "\n",
      "                                            ...                                \\\n",
      "  Adjusted Close ABER_ZG_5_15 ABER_SG_5_15  ...   VWMA_10       WCP  WILLR_14   \n",
      "0      -0.764863    -0.742809    -0.746216  ... -0.754006 -0.759885 -0.528163   \n",
      "1      -0.773410    -0.749188    -0.753052  ... -0.751685 -0.769232 -0.656546   \n",
      "2      -0.801190    -0.760590    -0.763502  ... -0.757157 -0.795497 -1.848760   \n",
      "3      -0.787656    -0.770829    -0.773050  ... -0.761867 -0.785623 -1.174511   \n",
      "4      -0.788843    -0.778777    -0.781264  ... -0.769220 -0.786479 -1.233658   \n",
      "\n",
      "                                                                        label  \n",
      "     WMA_10 ZL_EMA_10     ZS_30 Sentiment_1 Sentiment_2 Sentiment_3     Z_RET  \n",
      "0 -0.748230 -0.748139 -0.831984    0.333333    0.333333    0.333333  0.374971  \n",
      "1 -0.751573 -0.758219 -1.187641    0.333333    0.333333    0.333333  0.212956  \n",
      "2 -0.760953 -0.779360 -2.046091    0.333333    0.333333    0.333333  0.189423  \n",
      "3 -0.767234 -0.787598 -1.454881    0.333333    0.333333    0.333333  0.359483  \n",
      "4 -0.773237 -0.792708 -1.398341    0.333333    0.333333    0.333333  0.237946  \n",
      "\n",
      "[5 rows x 230 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert MultiIndex DataFrame to standard DataFrame\n",
    "df_standard = df_raw.reset_index()\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(df_standard.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "559823e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2008-01-02 00:00:00 -> 2019-12-10 00:00:00\n",
      "Valid: 2019-12-11 00:00:00 -> 2021-06-08 00:00:00\n",
      "Test:  2021-06-09 00:00:00 -> 2022-12-05 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Get unique sorted dates\n",
    "unique_dates = df_raw.index.get_level_values(\"datetime\").unique()\n",
    "n_total = len(unique_dates)\n",
    "\n",
    "# Compute split indices\n",
    "n_train = int(0.8 * n_total)\n",
    "n_valid = int(0.1 * n_total)\n",
    "n_test  = n_total - n_train - n_valid  # remaining\n",
    "\n",
    "# Slice date ranges\n",
    "train_dates = unique_dates[:n_train]\n",
    "valid_dates = unique_dates[n_train:n_train + n_valid]\n",
    "test_dates  = unique_dates[n_train + n_valid:]\n",
    "\n",
    "# Create splits\n",
    "df_train = df_raw.loc[train_dates]\n",
    "df_valid = df_raw.loc[valid_dates]\n",
    "df_test  = df_raw.loc[test_dates]\n",
    "\n",
    "# Show a quick check\n",
    "print(\"Train:\", df_train.index.get_level_values('datetime').min(), \"->\", df_train.index.get_level_values('datetime').max())\n",
    "print(\"Valid:\", df_valid.index.get_level_values('datetime').min(), \"->\", df_valid.index.get_level_values('datetime').max())\n",
    "print(\"Test: \", df_test.index.get_level_values('datetime').min(), \"->\", df_test.index.get_level_values('datetime').max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4a29d",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32cd5c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.8357\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Flatten DataFrames\n",
    "train_df = df_train.reset_index()\n",
    "valid_df = df_valid.reset_index()\n",
    "test_df  = df_test.reset_index()\n",
    "\n",
    "# Separate features and target\n",
    "FEATURE_COLS = [col[1] for col in df_raw.columns if col[0] == \"feature\"]\n",
    "TARGET_COL = \"Z_RET\"\n",
    "\n",
    "# Extract feature matrices and target vectors\n",
    "X_train = train_df[[(\"feature\", f) for f in FEATURE_COLS]].values\n",
    "y_train = train_df[(\"label\", TARGET_COL)].values\n",
    "\n",
    "X_valid = valid_df[[(\"feature\", f) for f in FEATURE_COLS]].values\n",
    "y_valid = valid_df[(\"label\", TARGET_COL)].values\n",
    "\n",
    "X_test = test_df[[(\"feature\", f) for f in FEATURE_COLS]].values\n",
    "y_test = test_df[(\"label\", TARGET_COL)].values\n",
    "\n",
    "# Optional: Standard scaling (depending on if you did CSZScoreNorm)\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_valid = scaler.transform(X_valid)\n",
    "# X_test  = scaler.transform(X_test)\n",
    "\n",
    "# Train XGBoost regressor\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_test = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred_test)\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e2941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ic(pred, label):\n",
    "    df = pd.DataFrame({'pred': pred, 'label': label})\n",
    "    ic = df['pred'].corr(df['label'])\n",
    "    ric = df['pred'].corr(df['label'], method='spearman')\n",
    "    return ic, ric\n",
    "\n",
    "def zscore(x):\n",
    "    return (x - x.mean()) / (x.std() + 1e-8)\n",
    "\n",
    "# Build Series with correct multi-index (datetime, instrument)\n",
    "test_index = df_test.index\n",
    "pred_series = pd.Series(y_pred_test, index=test_index)\n",
    "label_series = pd.Series(y_test, index=test_index)\n",
    "\n",
    "# Compute daily IC and RIC\n",
    "ics, rics = [], []\n",
    "for dt, pred_slice in pred_series.groupby(level=\"datetime\"):\n",
    "    label_slice = label_series.loc[dt]\n",
    "\n",
    "    # FIX: align values only, discard index\n",
    "    ic, ric = calc_ic(pred_slice.values, label_slice.values)\n",
    "    ics.append(ic)\n",
    "    rics.append(ric)\n",
    "\n",
    "# Portfolio vs benchmark returns\n",
    "daily_port_ret, daily_bench_ret = [], []\n",
    "\n",
    "for dt, pred_slice in pred_series.groupby(level=\"datetime\"):\n",
    "    label_slice = label_series.loc[dt]\n",
    "\n",
    "    # Portfolio: top 30 predicted\n",
    "    top30_idx = pred_slice.nlargest(30).index\n",
    "    port_ret = label_series.loc[top30_idx].mean()\n",
    "    daily_port_ret.append(port_ret)\n",
    "\n",
    "    # Benchmark: equal-weight average\n",
    "    bench_ret = label_slice.mean()\n",
    "    daily_bench_ret.append(bench_ret)\n",
    "\n",
    "# Compute AR (active return) and IR (information ratio)\n",
    "daily_port_ret = np.array(daily_port_ret)\n",
    "daily_bench_ret = np.array(daily_bench_ret)\n",
    "active_ret = daily_port_ret - daily_bench_ret\n",
    "\n",
    "AR = active_ret.mean()\n",
    "IR = AR / (active_ret.std() + 1e-12)\n",
    "\n",
    "# Final metrics\n",
    "metrics = {\n",
    "    \"IC\":     np.mean(ics),\n",
    "    \"ICIR\":   np.mean(ics) / (np.std(ics) + 1e-12),\n",
    "    \"RIC\":    np.mean(rics),\n",
    "    \"RICIR\":  np.mean(rics) / (np.std(rics) + 1e-12),\n",
    "    \"AR\":     AR,\n",
    "    \"IR\":     IR,\n",
    "}\n",
    "\n",
    "# Print metrics\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a7899",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "536b97b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.9315\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 1.  Prepare tensors and loaders\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "BATCH_SIZE   = 512\n",
    "DEVICE       = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "N_FEATURES   = X_train.shape[1]\n",
    "\n",
    "def make_loader(X, y, shuffle):\n",
    "    X_t = torch.tensor(X, dtype=torch.float32).unsqueeze(1)  # (batch, 1, features)\n",
    "    y_t = torch.tensor(y, dtype=torch.float32)\n",
    "    ds  = TensorDataset(X_t, y_t)\n",
    "    return DataLoader(ds, batch_size=BATCH_SIZE, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "train_loader = make_loader(X_train, y_train, shuffle=True)\n",
    "valid_loader = make_loader(X_valid, y_valid, shuffle=False)\n",
    "test_loader  = make_loader(X_test,  y_test,  shuffle=False)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 2.  Define a very small Transformer\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "class TransformerRegressor(nn.Module):\n",
    "    def __init__(self, n_features, d_model=128, nhead=4, num_layers=1, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(n_features, d_model)\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=4 * d_model,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "        self.head    = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x):                     # x: (batch, 1, n_features)\n",
    "        x = self.input_proj(x)                # -> (batch, 1, d_model)\n",
    "        x = self.encoder(x)                   # -> (batch, 1, d_model)\n",
    "        x = self.head(x[:, 0, :])             # first (and only) token\n",
    "        return x.squeeze(-1)                  # -> (batch,)\n",
    "\n",
    "model = TransformerRegressor(N_FEATURES).to(DEVICE)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 3.  Train\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "criterion   = nn.MSELoss()\n",
    "optimizer   = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "patience    = 10\n",
    "best_rmse   = np.inf\n",
    "wait_epochs = 0\n",
    "EPOCHS      = 5\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # ---- training ----\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # ---- validation ----\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_v, labels_v = [], []\n",
    "        for xb, yb in valid_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            preds_v.append(model(xb).cpu())\n",
    "            labels_v.append(yb)\n",
    "        preds_v  = torch.cat(preds_v).numpy()\n",
    "        labels_v = torch.cat(labels_v).numpy()\n",
    "        rmse_v   = mean_squared_error(labels_v, preds_v)\n",
    "\n",
    "    if rmse_v < best_rmse:\n",
    "        best_rmse   = rmse_v\n",
    "        wait_epochs = 0\n",
    "        best_state  = model.state_dict()\n",
    "    else:\n",
    "        wait_epochs += 1\n",
    "        if wait_epochs >= patience:\n",
    "            print(f\"Early stop at epoch {epoch:3d}  |  best val-RMSE = {best_rmse:.4f}\")\n",
    "            break\n",
    "\n",
    "# load the best model weights\n",
    "model.load_state_dict(best_state)\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# 4.  Test set inference\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_test = []\n",
    "    for xb, _ in test_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        preds_test.append(model(xb).cpu())\n",
    "    y_pred_test = torch.cat(preds_test).numpy()\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred_test)\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ic(pred, label):\n",
    "    df = pd.DataFrame({'pred': pred, 'label': label})\n",
    "    ic = df['pred'].corr(df['label'])\n",
    "    ric = df['pred'].corr(df['label'], method='spearman')\n",
    "    return ic, ric\n",
    "\n",
    "def zscore(x):\n",
    "    return (x - x.mean()) / (x.std() + 1e-8)\n",
    "\n",
    "# Build Series with correct multi-index (datetime, instrument)\n",
    "test_index = df_test.index\n",
    "pred_series = pd.Series(y_pred_test, index=test_index)\n",
    "label_series = pd.Series(y_test, index=test_index)\n",
    "\n",
    "# Compute daily IC and RIC\n",
    "ics, rics = [], []\n",
    "for dt, pred_slice in pred_series.groupby(level=\"datetime\"):\n",
    "    label_slice = label_series.loc[dt]\n",
    "\n",
    "    # FIX: align values only, discard index\n",
    "    ic, ric = calc_ic(pred_slice.values, label_slice.values)\n",
    "    ics.append(ic)\n",
    "    rics.append(ric)\n",
    "\n",
    "# Portfolio vs benchmark returns\n",
    "daily_port_ret, daily_bench_ret = [], []\n",
    "\n",
    "for dt, pred_slice in pred_series.groupby(level=\"datetime\"):\n",
    "    label_slice = label_series.loc[dt]\n",
    "\n",
    "    # Portfolio: top 30 predicted\n",
    "    top30_idx = pred_slice.nlargest(30).index\n",
    "    port_ret = label_series.loc[top30_idx].mean()\n",
    "    daily_port_ret.append(port_ret)\n",
    "\n",
    "    # Benchmark: equal-weight average\n",
    "    bench_ret = label_slice.mean()\n",
    "    daily_bench_ret.append(bench_ret)\n",
    "\n",
    "# Compute AR (active return) and IR (information ratio)\n",
    "daily_port_ret = np.array(daily_port_ret)\n",
    "daily_bench_ret = np.array(daily_bench_ret)\n",
    "active_ret = daily_port_ret - daily_bench_ret\n",
    "\n",
    "AR = active_ret.mean()\n",
    "IR = AR / (active_ret.std() + 1e-12)\n",
    "\n",
    "# Final metrics\n",
    "metrics = {\n",
    "    \"IC\":     np.mean(ics),\n",
    "    \"ICIR\":   np.mean(ics) / (np.std(ics) + 1e-12),\n",
    "    \"RIC\":    np.mean(rics),\n",
    "    \"RICIR\":  np.mean(rics) / (np.std(rics) + 1e-12),\n",
    "    \"AR\":     AR,\n",
    "    \"IR\":     IR,\n",
    "}\n",
    "\n",
    "# Print metrics\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d817124a",
   "metadata": {},
   "source": [
    "# Cross-validation on Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31fecb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_trans():\n",
    "\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────────\n",
    "    # 1.  Prepare tensors and loaders\n",
    "    # ──────────────────────────────────────────────────────────────\n",
    "    BATCH_SIZE   = 512\n",
    "    DEVICE       = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    N_FEATURES   = X_train.shape[1]\n",
    "\n",
    "    def make_loader(X, y, shuffle):\n",
    "        X_t = torch.tensor(X, dtype=torch.float32).unsqueeze(1)  # (batch, 1, features)\n",
    "        y_t = torch.tensor(y, dtype=torch.float32)\n",
    "        ds  = TensorDataset(X_t, y_t)\n",
    "        return DataLoader(ds, batch_size=BATCH_SIZE, shuffle=shuffle, drop_last=False)\n",
    "\n",
    "    train_loader = make_loader(X_train, y_train, shuffle=True)\n",
    "    valid_loader = make_loader(X_valid, y_valid, shuffle=False)\n",
    "    test_loader  = make_loader(X_test,  y_test,  shuffle=False)\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────────\n",
    "    # 2.  Define a very small Transformer\n",
    "    # ──────────────────────────────────────────────────────────────\n",
    "    class TransformerRegressor(nn.Module):\n",
    "        def __init__(self, n_features, d_model=128, nhead=4, num_layers=1, dropout=0.1):\n",
    "            super().__init__()\n",
    "            self.input_proj = nn.Linear(n_features, d_model)\n",
    "            enc_layer = nn.TransformerEncoderLayer(\n",
    "                d_model=d_model,\n",
    "                nhead=nhead,\n",
    "                dim_feedforward=4 * d_model,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "            )\n",
    "            self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n",
    "            self.head    = nn.Linear(d_model, 1)\n",
    "\n",
    "        def forward(self, x):                     # x: (batch, 1, n_features)\n",
    "            x = self.input_proj(x)                # -> (batch, 1, d_model)\n",
    "            x = self.encoder(x)                   # -> (batch, 1, d_model)\n",
    "            x = self.head(x[:, 0, :])             # first (and only) token\n",
    "            return x.squeeze(-1)                  # -> (batch,)\n",
    "\n",
    "    model = TransformerRegressor(N_FEATURES).to(DEVICE)\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────────\n",
    "    # 3.  Train\n",
    "    # ──────────────────────────────────────────────────────────────\n",
    "    criterion   = nn.MSELoss()\n",
    "    optimizer   = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    patience    = 10\n",
    "    best_rmse   = np.inf\n",
    "    wait_epochs = 0\n",
    "    EPOCHS      = 5\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        # ---- training ----\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # ---- validation ----\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            preds_v, labels_v = [], []\n",
    "            for xb, yb in valid_loader:\n",
    "                xb = xb.to(DEVICE)\n",
    "                preds_v.append(model(xb).cpu())\n",
    "                labels_v.append(yb)\n",
    "            preds_v  = torch.cat(preds_v).numpy()\n",
    "            labels_v = torch.cat(labels_v).numpy()\n",
    "            rmse_v   = mean_squared_error(labels_v, preds_v)\n",
    "\n",
    "        if rmse_v < best_rmse:\n",
    "            best_rmse   = rmse_v\n",
    "            wait_epochs = 0\n",
    "            best_state  = model.state_dict()\n",
    "        else:\n",
    "            wait_epochs += 1\n",
    "            if wait_epochs >= patience:\n",
    "                print(f\"Early stop at epoch {epoch:3d}  |  best val-RMSE = {best_rmse:.4f}\")\n",
    "                break\n",
    "\n",
    "    # load the best model weights\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────────\n",
    "    # 4.  Test set inference\n",
    "    # ──────────────────────────────────────────────────────────────\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_test = []\n",
    "        for xb, _ in test_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            preds_test.append(model(xb).cpu())\n",
    "        y_pred_test = torch.cat(preds_test).numpy()\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_pred_test)\n",
    "    print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "    def calc_ic(pred, label):\n",
    "        df = pd.DataFrame({'pred': pred, 'label': label})\n",
    "        ic = df['pred'].corr(df['label'])\n",
    "        ric = df['pred'].corr(df['label'], method='spearman')\n",
    "        return ic, ric\n",
    "\n",
    "    def zscore(x):\n",
    "        return (x - x.mean()) / (x.std() + 1e-8)\n",
    "\n",
    "    # Build Series with correct multi-index (datetime, instrument)\n",
    "    test_index = df_test.index\n",
    "    pred_series = pd.Series(y_pred_test, index=test_index)\n",
    "    label_series = pd.Series(y_test, index=test_index)\n",
    "\n",
    "    # Compute daily IC and RIC\n",
    "    ics, rics = [], []\n",
    "    for dt, pred_slice in pred_series.groupby(level=\"datetime\"):\n",
    "        label_slice = label_series.loc[dt]\n",
    "\n",
    "        # FIX: align values only, discard index\n",
    "        ic, ric = calc_ic(pred_slice.values, label_slice.values)\n",
    "        ics.append(ic)\n",
    "        rics.append(ric)\n",
    "\n",
    "    # Portfolio vs benchmark returns\n",
    "    daily_port_ret, daily_bench_ret = [], []\n",
    "\n",
    "    for dt, pred_slice in pred_series.groupby(level=\"datetime\"):\n",
    "        label_slice = label_series.loc[dt]\n",
    "\n",
    "        # Portfolio: top 30 predicted\n",
    "        top30_idx = pred_slice.nlargest(30).index\n",
    "        port_ret = label_series.loc[top30_idx].mean()\n",
    "        daily_port_ret.append(port_ret)\n",
    "\n",
    "        # Benchmark: equal-weight average\n",
    "        bench_ret = label_slice.mean()\n",
    "        daily_bench_ret.append(bench_ret)\n",
    "\n",
    "    # Compute AR (active return) and IR (information ratio)\n",
    "    daily_port_ret = np.array(daily_port_ret)\n",
    "    daily_bench_ret = np.array(daily_bench_ret)\n",
    "    active_ret = daily_port_ret - daily_bench_ret\n",
    "\n",
    "    AR = active_ret.mean()\n",
    "    IR = AR / (active_ret.std() + 1e-12)\n",
    "\n",
    "    # Final metrics\n",
    "    metrics = {\n",
    "        \"IC\":     np.mean(ics),\n",
    "        \"ICIR\":   np.mean(ics) / (np.std(ics) + 1e-12),\n",
    "        \"RIC\":    np.mean(rics),\n",
    "        \"RICIR\":  np.mean(rics) / (np.std(rics) + 1e-12),\n",
    "        \"AR\":     AR,\n",
    "        \"IR\":     IR,\n",
    "    }\n",
    "\n",
    "    # Print metrics\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e65876",
   "metadata": {},
   "outputs": [],
   "source": [
    "ic = []\n",
    "icir = []\n",
    "ric = []\n",
    "ricir = []\n",
    "\n",
    "\n",
    "# New metrics\n",
    "ar = []\n",
    "ir = []\n",
    "for seed in [i for i in range(5)]: \n",
    "    metrics = train_trans()\n",
    "\n",
    "    ic.append(metrics['IC'])\n",
    "    icir.append(metrics['ICIR'])\n",
    "    ric.append(metrics['RIC'])\n",
    "    ricir.append(metrics['RICIR'])\n",
    "    ar.append(metrics['AR'])\n",
    "    ir.append(metrics['IR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4b1f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "# Sample size\n",
    "n = len(ic)\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# t critical value for 95% confidence\n",
    "t_crit = t.ppf(0.975, df)  # two-tailed\n",
    "\n",
    "# Function to compute mean and 95% CI error\n",
    "def ci_95(arr):\n",
    "    mean = np.mean(arr)\n",
    "    se = np.std(arr, ddof=1) / np.sqrt(len(arr))\n",
    "    margin = t_crit * se\n",
    "    return mean, margin\n",
    "\n",
    "# Print each metric with 95% CI\n",
    "print(\"IC: {:.4f} pm {:.4f}\".format(*ci_95(ic)))\n",
    "print(\"ICIR: {:.4f} pm {:.4f}\".format(*ci_95(icir)))\n",
    "print(\"RIC: {:.4f} pm {:.4f}\".format(*ci_95(ric)))\n",
    "print(\"RICIR: {:.4f} pm {:.4f}\".format(*ci_95(ricir)))\n",
    "print(\"AR: {:.4f} pm {:.4f}\".format(*ci_95(ar)))\n",
    "print(\"IR: {:.4f} pm {:.4f}\".format(*ci_95(ir)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gabri_master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
