{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "500444bd",
   "metadata": {},
   "source": [
    "Dataset to use:\n",
    "https://www.kaggle.com/datasets/paultimothymooney/stock-market-data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38da795",
   "metadata": {},
   "source": [
    "A site to get thechnical indicators from:\n",
    "https://www.investopedia.com/articles/active-trading/011815/top-technical-indicators-rookie-traders.asp?utm_source=chatgpt.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f3e0bb",
   "metadata": {},
   "source": [
    "Piano:\n",
    "- Trovare indicatori da usare su una singola stock\n",
    "- Trovare indicatori da usare su tutto l indice (più semplici come mean e std sull ultimo dato e una window di 5, 10, 20) per esempio:\n",
    "    - Market index price\n",
    "    - Market index trading volume\n",
    "- Creare un nuovo dataset che usa questi indicatori"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260652db",
   "metadata": {},
   "source": [
    "Libreria da usare: pandas‑ta\n",
    "- contiene 130 indicatori già fatti (usarne una 50ina)\n",
    "\n",
    "\n",
    "Chat per spunto:\n",
    "https://chatgpt.com/share/681e1a2a-a944-8013-834e-2ef66c01417b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a822df85",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2706dd2",
   "metadata": {},
   "source": [
    "In this notebook we download our data from kaggle and then augment it with classic technical analysis indicators.\n",
    "We will use pandas-ta, an extension of pandas for Technical Analysis. \n",
    "\n",
    "Pandas-ta is a Numerical Time Series Feature Generator where the Time Series data is biased towards Financial Market data; typical data includes columns named :\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d98ea9",
   "metadata": {},
   "source": [
    "Dataset used: https://www.kaggle.com/datasets/paultimothymooney/stock-market-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c5fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"paultimothymooney/stock-market-data\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a7157a",
   "metadata": {},
   "source": [
    "## Basic Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825d143f",
   "metadata": {},
   "source": [
    "This is a quick overview about how the library works and the process of feature enrichment applied to one stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b96d9c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# re–add the old alias so pandas_ta can import it\n",
    "if not hasattr(np, \"NaN\"):\n",
    "    np.NaN = np.nan     # Needed by pandas_ta\n",
    "\n",
    "# We need to downgrade pandas to 1.5.3 for pandas_ta to work correctly\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "df = pd.DataFrame() # Empty DataFrame\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"data/sp500/csv/A.csv\", sep=\",\")\n",
    "# OR if you have yfinance installed\n",
    "# df = df.ta.ticker(\"aapl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a3a097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5804 entries, 0 to 5803\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Date            5804 non-null   object \n",
      " 1   Low             5804 non-null   float64\n",
      " 2   Open            5804 non-null   float64\n",
      " 3   Volume          5804 non-null   int64  \n",
      " 4   High            5804 non-null   float64\n",
      " 5   Close           5804 non-null   float64\n",
      " 6   Adjusted Close  5804 non-null   float64\n",
      "dtypes: float64(5), int64(1), object(1)\n",
      "memory usage: 317.5+ KB\n",
      "None\n",
      "         Date        Low       Open    Volume       High      Close  \\\n",
      "0  18-11-1999  28.612303  32.546494  62546380  35.765381  31.473534   \n",
      "1  19-11-1999  28.478184  30.713518  15234146  30.758226  28.880545   \n",
      "2  22-11-1999  28.657009  29.551144   6577870  31.473534  31.473534   \n",
      "3  23-11-1999  28.612303  30.400572   5975611  31.205294  28.612303   \n",
      "4  24-11-1999  28.612303  28.701717   4843231  29.998213  29.372318   \n",
      "\n",
      "   Adjusted Close  \n",
      "0       26.929760  \n",
      "1       24.711119  \n",
      "2       26.929760  \n",
      "3       24.481602  \n",
      "4       25.131901  \n"
     ]
    }
   ],
   "source": [
    "# Print DataFrame structure\n",
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4e8961d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gabriele\\AppData\\Local\\Temp\\ipykernel_20328\\2585312532.py:3: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df.set_index(pd.DatetimeIndex(df[\"Date\"]), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adjusted Close</th>\n",
       "      <th>CUMLOGRET_1</th>\n",
       "      <th>CUMPCTRET_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-12</th>\n",
       "      <td>149.910004</td>\n",
       "      <td>152.149994</td>\n",
       "      <td>1172300</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>151.350006</td>\n",
       "      <td>151.350006</td>\n",
       "      <td>1.570448</td>\n",
       "      <td>3.808802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07-12</th>\n",
       "      <td>151.130005</td>\n",
       "      <td>151.229996</td>\n",
       "      <td>1011100</td>\n",
       "      <td>154.350006</td>\n",
       "      <td>153.729996</td>\n",
       "      <td>153.729996</td>\n",
       "      <td>1.586051</td>\n",
       "      <td>3.884421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-12</th>\n",
       "      <td>153.479996</td>\n",
       "      <td>154.419998</td>\n",
       "      <td>1289900</td>\n",
       "      <td>156.990005</td>\n",
       "      <td>156.279999</td>\n",
       "      <td>156.279999</td>\n",
       "      <td>1.602502</td>\n",
       "      <td>3.965442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-12</th>\n",
       "      <td>152.679993</td>\n",
       "      <td>155.669998</td>\n",
       "      <td>1020200</td>\n",
       "      <td>156.699997</td>\n",
       "      <td>152.949997</td>\n",
       "      <td>152.949997</td>\n",
       "      <td>1.580964</td>\n",
       "      <td>3.859639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-12</th>\n",
       "      <td>153.380005</td>\n",
       "      <td>154.009995</td>\n",
       "      <td>188024</td>\n",
       "      <td>155.399994</td>\n",
       "      <td>155.399994</td>\n",
       "      <td>155.399994</td>\n",
       "      <td>1.596855</td>\n",
       "      <td>3.937482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Low        Open   Volume        High       Close  \\\n",
       "Date                                                                  \n",
       "2022-06-12  149.910004  152.149994  1172300  153.000000  151.350006   \n",
       "2022-07-12  151.130005  151.229996  1011100  154.350006  153.729996   \n",
       "2022-08-12  153.479996  154.419998  1289900  156.990005  156.279999   \n",
       "2022-09-12  152.679993  155.669998  1020200  156.699997  152.949997   \n",
       "2022-12-12  153.380005  154.009995   188024  155.399994  155.399994   \n",
       "\n",
       "            Adjusted Close  CUMLOGRET_1  CUMPCTRET_1  \n",
       "Date                                                  \n",
       "2022-06-12      151.350006     1.570448     3.808802  \n",
       "2022-07-12      153.729996     1.586051     3.884421  \n",
       "2022-08-12      156.279999     1.602502     3.965442  \n",
       "2022-09-12      152.949997     1.580964     3.859639  \n",
       "2022-12-12      155.399994     1.596855     3.937482  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VWAP requires the DataFrame index to be a DatetimeIndex.\n",
    "# Replace \"datetime\" with the appropriate column from your DataFrame\n",
    "df.set_index(pd.DatetimeIndex(df[\"Date\"]), inplace=True)\n",
    "\n",
    "# Drop the \"Date\" column if it's no longer needed\n",
    "df.drop(columns=[\"Date\"], inplace=True)\n",
    "\n",
    "# Calculate Returns and append to the df DataFrame\n",
    "# This automatically calculates the log return and percent return \n",
    "#  from the 'close' field in our dataset using the pandas-ta indicator\n",
    "df.ta.log_return(cumulative=True, append=True)\n",
    "df.ta.percent_return(cumulative=True, append=True)\n",
    "\n",
    "# New Columns with results\n",
    "df.columns\n",
    "\n",
    "# Take a peek\n",
    "df.tail()\n",
    "\n",
    "# vv Continue Post Processing vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94854b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas TA - Technical Analysis Indicators - v0.3.14b0\n",
      "Total Indicators & Utilities: 205\n",
      "Abbreviations:\n",
      "    aberration, above, above_value, accbands, ad, adosc, adx, alma, amat, ao, aobv, apo, aroon, atr, bbands, below, below_value, bias, bop, brar, cci, cdl_pattern, cdl_z, cfo, cg, chop, cksp, cmf, cmo, coppock, cross, cross_value, cti, decay, decreasing, dema, dm, donchian, dpo, ebsw, efi, ema, entropy, eom, er, eri, fisher, fwma, ha, hilo, hl2, hlc3, hma, hwc, hwma, ichimoku, increasing, inertia, jma, kama, kc, kdj, kst, kurtosis, kvo, linreg, log_return, long_run, macd, mad, massi, mcgd, median, mfi, midpoint, midprice, mom, natr, nvi, obv, ohlc4, pdist, percent_return, pgo, ppo, psar, psl, pvi, pvo, pvol, pvr, pvt, pwma, qqe, qstick, quantile, rma, roc, rsi, rsx, rvgi, rvi, short_run, sinwma, skew, slope, sma, smi, squeeze, squeeze_pro, ssf, stc, stdev, stoch, stochrsi, supertrend, swma, t3, td_seq, tema, thermo, tos_stdevall, trima, trix, true_range, tsi, tsignals, ttm_trend, ui, uo, variance, vhf, vidya, vortex, vp, vwap, vwma, wcp, willr, wma, xsignals, zlma, zscore\n",
      "\n",
      "Candle Patterns:\n",
      "    2crows, 3blackcrows, 3inside, 3linestrike, 3outside, 3starsinsouth, 3whitesoldiers, abandonedbaby, advanceblock, belthold, breakaway, closingmarubozu, concealbabyswall, counterattack, darkcloudcover, doji, dojistar, dragonflydoji, engulfing, eveningdojistar, eveningstar, gapsidesidewhite, gravestonedoji, hammer, hangingman, harami, haramicross, highwave, hikkake, hikkakemod, homingpigeon, identical3crows, inneck, inside, invertedhammer, kicking, kickingbylength, ladderbottom, longleggeddoji, longline, marubozu, matchinglow, mathold, morningdojistar, morningstar, onneck, piercing, rickshawman, risefall3methods, separatinglines, shootingstar, shortline, spinningtop, stalledpattern, sticksandwich, takuri, tasukigap, thrusting, tristar, unique3river, upsidegap2crows, xsidegap3methods\n"
     ]
    }
   ],
   "source": [
    "# Help about this, 'ta', extension\n",
    "# help(df.ta)\n",
    "\n",
    "# List of all indicators\n",
    "df.ta.indicators()\n",
    "\n",
    "# # Help about an indicator such as bbands\n",
    "# help(ta.bbands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f03a205",
   "metadata": {},
   "source": [
    "Pandas-ta offers a variety of technical indicators. To enrich our dataset, we will use the majority of them as additional features.\n",
    "\n",
    "Pandas-ta offer pre-packed 'strategies' including a subset of indicators.\n",
    "\n",
    "Two popular one are\n",
    "- ta.CommonStrategy  (subset of the most commonly used)\n",
    "- ta.AllStrategy     (this includes all the indicators, usually used for feature generation)\n",
    "\n",
    "We will focus on ta.AllStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a6481eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (5804, 8)\n"
     ]
    }
   ],
   "source": [
    "# print dataset size\n",
    "print(\"Dataset size:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abe52b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common Strategy\n",
      "Strategy(name='Common Price and Volume SMAs', ta=[{'kind': 'sma', 'length': 10}, {'kind': 'sma', 'length': 20}, {'kind': 'sma', 'length': 50}, {'kind': 'sma', 'length': 200}, {'kind': 'sma', 'close': 'volume', 'length': 20, 'prefix': 'VOL'}], description='Common Price SMAs: 10, 20, 50, 200 and Volume SMA: 20.', created='Tuesday May 13, 2025, NYSE: 7:23:52, Local: 11:23:52 ora legale Europa occidentale, Day 133/365 (36.00%)')\n",
      "{'kind': 'sma', 'length': 10}\n",
      "{'kind': 'sma', 'length': 20}\n",
      "{'kind': 'sma', 'length': 50}\n",
      "{'kind': 'sma', 'length': 200}\n",
      "{'kind': 'sma', 'close': 'volume', 'length': 20, 'prefix': 'VOL'}\n",
      "All Strategy\n",
      "Strategy(name='All', ta=None, description='All the indicators with their default settings. Pandas TA default.', created='Tuesday May 13, 2025, NYSE: 7:23:52, Local: 11:23:52 ora legale Europa occidentale, Day 133/365 (36.00%)')\n"
     ]
    }
   ],
   "source": [
    "# Common Strategy\n",
    "print(\"Common Strategy\")\n",
    "print(ta.CommonStrategy)\n",
    "\n",
    "for indicator in ta.CommonStrategy.ta:\n",
    "    print(indicator)\n",
    "\n",
    "\n",
    "# All Strategy\n",
    "print(\"All Strategy\")\n",
    "print(ta.AllStrategy)\n",
    "# While common strategy is a defined subset of all indicators, \n",
    "#  all strategy dinamically generates a list of all indicators from the current list\n",
    "#  It is a special command\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc7cc8a",
   "metadata": {},
   "source": [
    "Here we choose the indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a2bd852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [00:01, 66.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Select first 1000 elements in the dataframe\n",
    "df = df.iloc[:1000]\n",
    "\n",
    "# for indicator in ta.AllStrategy.ta:\n",
    "df.ta.strategy(\n",
    "    ta.AllStrategy,\n",
    "    calculate=True,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d415383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Low       Open   Volume       High      Close  \\\n",
      "Date                                                              \n",
      "2005-09-27  19.100000  21.049999   961200  21.400000  19.299999   \n",
      "2005-09-28  19.200001  19.299999  5747900  20.530001  20.500000   \n",
      "2005-09-29  20.100000  20.400000  1078200  20.580000  20.209999   \n",
      "2005-09-30  20.180000  20.260000  3123300  21.049999  21.010000   \n",
      "2005-03-10  20.900000  20.900000  1057900  21.750000  21.500000   \n",
      "\n",
      "            Adjusted Close  CUMLOGRET_1  CUMPCTRET_1  ABER_ZG_5_15  \\\n",
      "Date                                                                 \n",
      "2005-09-27       18.194910     0.000000     0.000000           NaN   \n",
      "2005-09-28       19.326204     0.060320     0.062176           NaN   \n",
      "2005-09-29       19.052805     0.046072     0.047150           NaN   \n",
      "2005-09-30       19.807001     0.084893     0.088601           NaN   \n",
      "2005-03-10       20.268940     0.107948     0.113990     20.487333   \n",
      "\n",
      "            ABER_SG_5_15  ...  VIDYA_14  VTXP_14  VTXM_14     VWAP_D  VWMA_10  \\\n",
      "Date                      ...                                                   \n",
      "2005-09-27           NaN  ...       NaN      NaN      NaN  19.933333      NaN   \n",
      "2005-09-28           NaN  ...       NaN      NaN      NaN  20.076667      NaN   \n",
      "2005-09-29           NaN  ...       NaN      NaN      NaN  20.296666      NaN   \n",
      "2005-09-30           NaN  ...       NaN      NaN      NaN  20.746667      NaN   \n",
      "2005-03-10           NaN  ...       NaN      NaN      NaN  21.383333      NaN   \n",
      "\n",
      "                WCP  WILLR_14  WMA_10  ZL_EMA_10  ZS_30  \n",
      "Date                                                     \n",
      "2005-09-27  19.7750       NaN     NaN        NaN    NaN  \n",
      "2005-09-28  20.1825       NaN     NaN        NaN    NaN  \n",
      "2005-09-29  20.2750       NaN     NaN        NaN    NaN  \n",
      "2005-09-30  20.8125       NaN     NaN        NaN    NaN  \n",
      "2005-03-10  21.4125       NaN     NaN        NaN    NaN  \n",
      "\n",
      "[5 rows x 226 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 rows to check the new columns\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4349e6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Low', 'Open', 'Volume', 'High', 'Close', 'Adjusted Close', 'CUMLOGRET_1', 'CUMPCTRET_1', 'ABER_ZG_5_15', 'ABER_SG_5_15', 'ABER_XG_5_15', 'ABER_ATR_5_15', 'ACCBL_20', 'ACCBM_20', 'ACCBU_20', 'AD', 'ADOSC_3_10', 'ADX_14', 'DMP_14', 'DMN_14', 'ALMA_10_6.0_0.85', 'AMATe_LR_8_21_2', 'AMATe_SR_8_21_2', 'AO_5_34', 'OBV', 'OBV_min_2', 'OBV_max_2', 'OBVe_4', 'OBVe_12', 'AOBV_LR_2', 'AOBV_SR_2', 'APO_12_26', 'AROOND_14', 'AROONU_14', 'AROONOSC_14', 'ATRr_14', 'BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0', 'BBB_5_2.0', 'BBP_5_2.0', 'BIAS_SMA_26', 'BOP', 'AR_26', 'BR_26', 'CCI_14_0.015', 'CDL_DOJI_10_0.1', 'CDL_INSIDE', 'open_Z_30_1', 'high_Z_30_1', 'low_Z_30_1', 'close_Z_30_1', 'CFO_9', 'CG_10', 'CHOP_14_1_100', 'CKSPl_10_3_20', 'CKSPs_10_3_20', 'CMF_20', 'CMO_14', 'COPC_11_14_10', 'CTI_12', 'LDECAY_5', 'DEC_1', 'DEMA_10', 'DCL_20_20', 'DCM_20_20', 'DCU_20_20', 'DPO_20', 'EBSW_40_10', 'EFI_13', 'EMA_10', 'ENTP_10', 'EOM_14_100000000', 'ER_10', 'BULLP_13', 'BEARP_13', 'FISHERT_9_1', 'FISHERTs_9_1', 'FWMA_10', 'HA_open', 'HA_high', 'HA_low', 'HA_close', 'HILO_13_21', 'HILOl_13_21', 'HILOs_13_21', 'HL2', 'HLC3', 'HMA_10', 'HWM', 'HWU', 'HWL', 'HWMA_0.2_0.1_0.1', 'ISA_9', 'ISB_26', 'ITS_9', 'IKS_26', 'ICS_26', 'INC_1', 'INERTIA_20_14', 'JMA_7_0', 'KAMA_10_2_30', 'KCLe_20_2', 'KCBe_20_2', 'KCUe_20_2', 'K_9_3', 'D_9_3', 'J_9_3', 'KST_10_15_20_30_10_10_10_15', 'KSTs_9', 'KURT_30', 'KVO_34_55_13', 'KVOs_34_55_13', 'LR_14', 'LOGRET_1', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9', 'MAD_30', 'MASSI_9_25', 'MCGD_10', 'MEDIAN_30', 'MFI_14', 'MIDPOINT_2', 'MIDPRICE_2', 'MOM_10', 'NATR_14', 'NVI_1', 'OHLC4', 'PDIST', 'PCTRET_1', 'PGO_14', 'PPO_12_26_9', 'PPOh_12_26_9', 'PPOs_12_26_9', 'PSARl_0.02_0.2', 'PSARs_0.02_0.2', 'PSARaf_0.02_0.2', 'PSARr_0.02_0.2', 'PSL_12', 'PVI_1', 'PVO_12_26_9', 'PVOh_12_26_9', 'PVOs_12_26_9', 'PVOL', 'PVR', 'PVT', 'PWMA_10', 'QQE_14_5_4.236', 'QQE_14_5_4.236_RSIMA', 'QQEl_14_5_4.236', 'QQEs_14_5_4.236', 'QS_10', 'QTL_30_0.5', 'RMA_10', 'ROC_10', 'RSI_14', 'RSX_14', 'RVGI_14_4', 'RVGIs_14_4', 'RVI_14', 'SINWMA_14', 'SKEW_30', 'SLOPE_1', 'SMA_10', 'SMI_5_20_5', 'SMIs_5_20_5', 'SMIo_5_20_5', 'SQZ_20_2.0_20_1.5', 'SQZ_ON', 'SQZ_OFF', 'SQZ_NO', 'SQZPRO_20_2.0_20_2_1.5_1', 'SQZPRO_ON_WIDE', 'SQZPRO_ON_NORMAL', 'SQZPRO_ON_NARROW', 'SQZPRO_OFF', 'SQZPRO_NO', 'SSF_10_2', 'STC_10_12_26_0.5', 'STCmacd_10_12_26_0.5', 'STCstoch_10_12_26_0.5', 'STDEV_30', 'STOCHk_14_3_3', 'STOCHd_14_3_3', 'STOCHRSIk_14_14_3_3', 'STOCHRSId_14_14_3_3', 'SUPERT_7_3.0', 'SUPERTd_7_3.0', 'SUPERTl_7_3.0', 'SUPERTs_7_3.0', 'SWMA_10', 'T3_10_0.7', 'TEMA_10', 'THERMO_20_2_0.5', 'THERMOma_20_2_0.5', 'THERMOl_20_2_0.5', 'THERMOs_20_2_0.5', 'TOS_STDEVALL_LR', 'TOS_STDEVALL_L_1', 'TOS_STDEVALL_U_1', 'TOS_STDEVALL_L_2', 'TOS_STDEVALL_U_2', 'TOS_STDEVALL_L_3', 'TOS_STDEVALL_U_3', 'TRIMA_10', 'TRIX_30_9', 'TRIXs_30_9', 'TRUERANGE_1', 'TSI_13_25_13', 'TSIs_13_25_13', 'TTM_TRND_6', 'UI_14', 'UO_7_14_28', 'VAR_30', 'VHF_28', 'VIDYA_14', 'VTXP_14', 'VTXM_14', 'VWAP_D', 'VWMA_10', 'WCP', 'WILLR_14', 'WMA_10', 'ZL_EMA_10', 'ZS_30']\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78b50fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low: 43.81258773803711\n",
      "Open: 44.12553787231445\n",
      "Volume: 2044994.0\n",
      "High: 44.70672225952149\n",
      "Close: 44.21495056152344\n",
      "Adjusted Close: 37.83172225952149\n",
      "CUMLOGRET_1: 0.3399159894355293\n",
      "CUMPCTRET_1: 0.4048295650812219\n",
      "ABER_ZG_5_15: 44.10169296264648\n",
      "ABER_SG_5_15: 46.33022283947069\n",
      "ABER_XG_5_15: 41.87316308582227\n",
      "ABER_ATR_5_15: 2.2285298768242123\n",
      "ACCBL_20: 33.68751549934111\n",
      "ACCBM_20: 37.824123764038085\n",
      "ACCBU_20: 41.656488659131156\n",
      "AD: -33820652.1499736\n",
      "ADOSC_3_10: 3624425.78438285\n",
      "ADX_14: 30.970826395501806\n",
      "DMP_14: 0.7698087535902579\n",
      "DMN_14: 0.4178428459244688\n",
      "ALMA_10_6.0_0.85: 42.84267125024127\n",
      "AMATe_LR_8_21_2: 1.0\n",
      "AMATe_SR_8_21_2: 0.0\n",
      "AO_5_34: 8.156084167256076\n",
      "OBV: 21058212.0\n",
      "OBV_min_2: 21058212.0\n",
      "OBV_max_2: 23103206.0\n",
      "OBVe_4: 21750153.557137266\n",
      "OBVe_12: 17452583.708339468\n",
      "AOBV_LR_2: 1.0\n",
      "AOBV_SR_2: 0.0\n",
      "APO_12_26: 7.387212924468216\n",
      "AROOND_14: 7.14285714285714\n",
      "AROONU_14: 71.42857142857143\n",
      "AROONOSC_14: 64.28571428571429\n",
      "ATRr_14: 2.1868621148306424\n",
      "BBL_5_2.0: 43.2519390599802\n",
      "BBM_5_2.0: 44.21495056152344\n",
      "BBU_5_2.0: 45.17796206306667\n",
      "BBB_5_2.0: 4.35604468313604\n",
      "BBP_5_2.0: 0.5\n",
      "BIAS_SMA_26: 0.23648780229212285\n",
      "BOP: 0.09999914672855674\n",
      "AR_26: 112.94120918425428\n",
      "BR_26: 172.77349899680888\n",
      "CCI_14_0.015: 65.57437888893499\n",
      "CDL_DOJI_10_0.1: 100.0\n",
      "CDL_INSIDE: 1.0\n",
      "open_Z_30_1: 1.3423691551481827\n",
      "high_Z_30_1: 1.2998046659164455\n",
      "low_Z_30_1: 1.442639497640416\n",
      "close_Z_30_1: 1.3345024078541163\n",
      "CFO_9: -0.3145725576774584\n",
      "CG_10: -5.466481262514934\n",
      "CHOP_14_1_100: 25.94607354729429\n",
      "CKSPl_10_3_20: 39.69069970988477\n",
      "CKSPs_10_3_20: 33.17260284761691\n",
      "CMF_20: 0.2815711125068277\n",
      "CMO_14: 26.323190608083834\n",
      "COPC_11_14_10: 86.7883631336084\n",
      "CTI_12: 0.6304887396175402\n",
      "LDECAY_5: 44.21495056152344\n",
      "DEC_1: 1.0\n",
      "DEMA_10: 45.266626195238814\n",
      "DCL_20_20: 27.315807342529297\n",
      "DCM_20_20: 36.547746658325195\n",
      "DCU_20_20: 45.77968597412109\n",
      "DPO_20: 2.4611057281494126\n",
      "EBSW_40_10: 0.9914184436609097\n",
      "EFI_13: 5414752.520900386\n",
      "EMA_10: 42.46649723451864\n",
      "ENTP_10: 3.5073480739934957\n",
      "EOM_14_100000000: 22.84474800189582\n",
      "ER_10: 0.1390730422793079\n",
      "BULLP_13: 3.126060658922107\n",
      "BEARP_13: 2.231926137437725\n",
      "FISHERT_9_1: 1.938573910291912\n",
      "FISHERTs_9_1: 2.136751758983781\n",
      "FWMA_10: 43.996106581254445\n",
      "HA_open: 43.80248079538063\n",
      "HA_high: 44.70672225952149\n",
      "HA_low: 43.80248079538063\n",
      "HA_close: 44.21494960784912\n",
      "HILO_13_21: 36.36785534449986\n",
      "HILOl_13_21: 36.36785534449986\n",
      "HILOs_13_21: nan\n",
      "HL2: 44.2596549987793\n",
      "HLC3: 44.24475351969401\n",
      "HMA_10: 44.43216257191668\n",
      "HWM: 50.60901643670106\n",
      "HWU: 57.83730971388015\n",
      "HWL: 43.38072315952197\n",
      "HWMA_0.2_0.1_0.1: 50.60901643670106\n",
      "ISA_9: 42.54962348937988\n",
      "ISB_26: 48.79738712310791\n",
      "ITS_9: 43.365522384643555\n",
      "IKS_26: 36.547746658325195\n",
      "ICS_26: 32.77002716064453\n",
      "INC_1: 0.0\n",
      "INERTIA_20_14: 48.67395999649853\n",
      "JMA_7_0: 44.145753053507875\n",
      "KAMA_10_2_30: 43.21489950659741\n",
      "KCLe_20_2: 36.14349233022717\n",
      "KCBe_20_2: 40.24052349986412\n",
      "KCUe_20_2: 44.33755466950107\n",
      "K_9_3: 71.28528449973213\n",
      "D_9_3: 77.63291263284641\n",
      "J_9_3: 58.590028233503546\n",
      "KST_10_15_20_30_10_10_10_15: 22922.81597364204\n",
      "KSTs_9: 6922.913139278173\n",
      "KURT_30: -1.8224009589424264\n",
      "KVO_34_55_13: 484741.6877103289\n",
      "KVOs_34_55_13: 364707.34333864984\n",
      "LR_14: 45.56273533747746\n",
      "LOGRET_1: -0.0010106460163969704\n",
      "MACD_12_26_9: 1.9834591809201143\n",
      "MACDh_12_26_9: 1.079046659110394\n",
      "MACDs_12_26_9: 0.9044125218097203\n",
      "MAD_30: 6.486051483154295\n",
      "MASSI_9_25: 22.017802342693052\n",
      "MCGD_10: 34.127907741393535\n",
      "MEDIAN_30: 31.11587905883789\n",
      "MFI_14: 79.04550995811918\n",
      "MIDPOINT_2: 44.2373046875\n",
      "MIDPRICE_2: 43.92435646057129\n",
      "MOM_10: 0.9388427734375\n",
      "NATR_14: 4.378630760124705\n",
      "NVI_1: 1010.4493072607142\n",
      "OHLC4: 44.21494960784912\n",
      "PDIST: 1.8329772949218888\n",
      "PCTRET_1: -0.0010101354857148248\n",
      "PGO_14: 1.0807267448185305\n",
      "PPO_12_26_9: 20.658620122914705\n",
      "PPOh_12_26_9: 7.862952371915693\n",
      "PPOs_12_26_9: 12.795667750999012\n",
      "PSARl_0.02_0.2: 40.2593276445193\n",
      "PSARs_0.02_0.2: nan\n",
      "PSARaf_0.02_0.2: 0.14\n",
      "PSARr_0.02_0.2: 0.0\n",
      "PSL_12: 41.666666666666664\n",
      "PVI_1: 1073.6914999861197\n",
      "PVO_12_26_9: -21.251556361189927\n",
      "PVOh_12_26_9: -7.076953056396057\n",
      "PVOs_12_26_9: -14.17460330479387\n",
      "PVOL: 90419308.60861206\n",
      "PVR: 4.0\n",
      "PVT: 540990615.0235336\n",
      "PWMA_10: 43.26065319776535\n",
      "QQE_14_5_4.236: 55.31786576406705\n",
      "QQE_14_5_4.236_RSIMA: 62.92395819576881\n",
      "QQEl_14_5_4.236: 55.31786576406705\n",
      "QQEs_14_5_4.236: nan\n",
      "QS_10: 0.16988601684570312\n",
      "QTL_30_0.5: 31.11587905883789\n",
      "RMA_10: 40.36430593974142\n",
      "ROC_10: 2.1694251665025353\n",
      "RSI_14: 63.16159530404192\n",
      "RSX_14: 84.72234810313253\n",
      "RVGI_14_4: 0.18980942830984662\n",
      "RVGIs_14_4: 0.22204512809147153\n",
      "RVI_14: 41.67664679628157\n",
      "SINWMA_14: 42.356616574373945\n",
      "SKEW_30: 0.3869422452310704\n",
      "SLOPE_1: -0.044708251953125\n",
      "SMA_10: 43.41469955444336\n",
      "SMI_5_20_5: 0.3689527647934937\n",
      "SMIs_5_20_5: 0.3662517168680706\n",
      "SMIo_5_20_5: 0.0027010479254230835\n",
      "SQZ_20_2.0_20_1.5: 13.359859784444174\n",
      "SQZ_ON: 0.0\n",
      "SQZ_OFF: 1.0\n",
      "SQZ_NO: 0.0\n",
      "SQZPRO_20_2.0_20_2_1.5_1: 13.359859784444174\n",
      "SQZPRO_ON_WIDE: 0.0\n",
      "SQZPRO_ON_NORMAL: 0.0\n",
      "SQZPRO_ON_NARROW: 0.0\n",
      "SQZPRO_OFF: 1.0\n",
      "SQZPRO_NO: 0.0\n",
      "SSF_10_2: 44.0878394390063\n",
      "STC_10_12_26_0.5: 0.0\n",
      "STCmacd_10_12_26_0.5: 1.9834591809201143\n",
      "STCstoch_10_12_26_0.5: 0.0\n",
      "STDEV_30: 6.876571175453217\n",
      "STOCHk_14_3_3: 89.13097645400829\n",
      "STOCHd_14_3_3: 89.59231199209076\n",
      "STOCHRSIk_14_14_3_3: 87.20355230801904\n",
      "STOCHRSId_14_14_3_3: 88.88206104185969\n",
      "SUPERT_7_3.0: 38.51063718193236\n",
      "SUPERTd_7_3.0: 1.0\n",
      "SUPERTl_7_3.0: 38.51063718193236\n",
      "SUPERTs_7_3.0: nan\n",
      "SWMA_10: 43.322305552164714\n",
      "T3_10_0.7: 42.5281729023869\n",
      "TEMA_10: 45.39922349766902\n",
      "THERMO_20_2_0.5: 0.8047180175781321\n",
      "THERMOma_20_2_0.5: 1.5259849035882114\n",
      "THERMOl_20_2_0.5: 1.0\n",
      "THERMOs_20_2_0.5: 1.0\n",
      "TOS_STDEVALL_LR: 40.83307669131919\n",
      "TOS_STDEVALL_L_1: 23.441614852716214\n",
      "TOS_STDEVALL_U_1: 58.22453852992217\n",
      "TOS_STDEVALL_L_2: 6.050153014113235\n",
      "TOS_STDEVALL_U_2: 75.61600036852515\n",
      "TOS_STDEVALL_L_3: -11.341308824489744\n",
      "TOS_STDEVALL_U_3: 93.00746220712813\n",
      "TRIMA_10: 43.222708808051216\n",
      "TRIX_30_9: -0.7187833207863537\n",
      "TRIXs_30_9: -0.8362499956807193\n",
      "TRUERANGE_1: 0.8941345214843821\n",
      "TSI_13_25_13: 18.971556841253847\n",
      "TSIs_13_25_13: 2.627244101221488\n",
      "TTM_TRND_6: 1.0\n",
      "UI_14: 1.8036217428861865\n",
      "UO_7_14_28: 62.56068364343987\n",
      "VAR_30: 47.28723113107403\n",
      "VHF_28: 0.5944700400428157\n",
      "VIDYA_14: 41.015041369145486\n",
      "VTXP_14: 1.2084507057487488\n",
      "VTXM_14: 0.7267606222849661\n",
      "VWAP_D: 44.24475351969401\n",
      "VWMA_10: 43.5311010743627\n",
      "WCP: 44.23730278015137\n",
      "WILLR_14: -9.776535846813427\n",
      "WMA_10: 43.67928244850852\n",
      "ZL_EMA_10: 44.40719596111693\n",
      "ZS_30: 1.3345024078541163\n"
     ]
    }
   ],
   "source": [
    "# Print all column names and their values for the 30th row using a for loop\n",
    "row = df.iloc[200]\n",
    "for col, val in row.items():\n",
    "    print(f\"{col}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8c56a5",
   "metadata": {},
   "source": [
    "We select only those indicator that never get a nan value after 35 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "338d0c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with at least one NaN between rows 100 and 1000:\n",
      "DPO_20\n",
      "EBSW_40_10\n",
      "HILOl_13_21\n",
      "HILOs_13_21\n",
      "ISA_9\n",
      "ISB_26\n",
      "ICS_26\n",
      "KST_10_15_20_30_10_10_10_15\n",
      "KSTs_9\n",
      "KVO_34_55_13\n",
      "KVOs_34_55_13\n",
      "PSARl_0.02_0.2\n",
      "PSARs_0.02_0.2\n",
      "QQEl_14_5_4.236\n",
      "QQEs_14_5_4.236\n",
      "SUPERTl_7_3.0\n",
      "SUPERTs_7_3.0\n",
      "TRIXs_30_9\n"
     ]
    }
   ],
   "source": [
    "nan_features = df.iloc[35:1000].isna().any()\n",
    "features_with_nan = nan_features[nan_features].index.tolist()\n",
    "print(\"Features with at least one NaN between rows 100 and 1000:\")\n",
    "for feature in features_with_nan:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3ded7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We drop the previous indicators\n",
    "cols_to_drop = [\n",
    "    \"DPO_20\",\n",
    "    \"EBSW_40_10\",\n",
    "    \"HILOl_13_21\",\n",
    "    \"HILOs_13_21\",\n",
    "    \"ISA_9\",\n",
    "    \"ISB_26\",\n",
    "    \"ICS_26\",\n",
    "    \"KST_10_15_20_30_10_10_10_15\",\n",
    "    \"KSTs_9\",\n",
    "    \"KVO_34_55_13\",\n",
    "    \"KVOs_34_55_13\",\n",
    "    \"PSARl_0.02_0.2\",\n",
    "    \"PSARs_0.02_0.2\",\n",
    "    \"QQEl_14_5_4.236\",\n",
    "    \"QQEs_14_5_4.236\",\n",
    "    \"SUPERTl_7_3.0\",\n",
    "    \"SUPERTs_7_3.0\",\n",
    "    \"TRIXs_30_9\"\n",
    "]\n",
    "df = df.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "\n",
    "# We set remaining nan datapoints to 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# Drop the first 50 datapoints from the DataFrame\n",
    "df = df.iloc[50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8a6261",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d11346",
   "metadata": {},
   "source": [
    "In this section we will create a dataset of stocks active in between 2008 and 2022, enrich the dataset with new features and then create a second dataset with market informations for the same period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea695aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# re–add the old alias so pandas_ta can import it\n",
    "if not hasattr(np, \"NaN\"):\n",
    "    np.NaN = np.nan     # Needed by pandas_ta\n",
    "\n",
    "# We need to downgrade pandas to 1.5.3 for pandas_ta to work correctly\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b6fc23",
   "metadata": {},
   "source": [
    "Utility code to delete all files (i.e stocks) that do not have datapoints in between 01-10-2007 and 2022.\n",
    "\n",
    "We will then compute all the metrics for 01-10-2007 onward and keep all the datapoints from 2008.\n",
    "We start computing metrics from 01-10-2007, becouse some indicators lag in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1ee22824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files NOT active in both 01-10-2007 and 12-12-2022: 2\n",
      "MSCI.csv\n",
      "ULTA.csv\n"
     ]
    }
   ],
   "source": [
    "# This just counts them for a specific folder\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_folder = os.path.join(\"data\", \"cleaned\", \"sp500\", \"csv\")\n",
    "files = [f for f in os.listdir(csv_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "active_both_dates = []\n",
    "not_active_both_dates = []\n",
    "\n",
    "for f in files:\n",
    "    path = os.path.join(csv_folder, f)\n",
    "    try:\n",
    "        df_tmp = pd.read_csv(path)\n",
    "        # Check if both dates are present in the 'Date' column\n",
    "        if \"Date\" in df_tmp.columns:\n",
    "            dates = df_tmp[\"Date\"].astype(str)\n",
    "        else:\n",
    "            # If no header, assume first column is date\n",
    "            dates = df_tmp.iloc[:, 0].astype(str)\n",
    "        if (\"01-10-2007\" in dates.values) and (\"12-12-2022\" in dates.values):\n",
    "            active_both_dates.append(f)\n",
    "        else:\n",
    "            not_active_both_dates.append(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not read {f}: {e}\")\n",
    "\n",
    "print(f\"Files NOT active in both 01-10-2007 and 12-12-2022: {len(not_active_both_dates)}\")\n",
    "for fname in not_active_both_dates:\n",
    "    print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a12b4275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forbes2000: 3 files NOT active in both 01-10-2007 and 12-12-2022\n",
      "nasdaq: 8 files NOT active in both 01-10-2007 and 12-12-2022\n",
      "nyse: 8 files NOT active in both 01-10-2007 and 12-12-2022\n",
      "sp500: 2 files NOT active in both 01-10-2007 and 12-12-2022\n"
     ]
    }
   ],
   "source": [
    "# This goes through all the folders and deletes the files that are not active in both dates\n",
    "\n",
    "folders = ['forbes2000', 'nasdaq', 'nyse', 'sp500']\n",
    "\n",
    "for folder in folders:\n",
    "    csv_folder = os.path.join(\"data\", \"cleaned\", folder, \"csv\")\n",
    "    files = [f for f in os.listdir(csv_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "    not_active_both_dates = []\n",
    "\n",
    "    for f in files:\n",
    "        path = os.path.join(csv_folder, f)\n",
    "        try:\n",
    "            df_tmp = pd.read_csv(path)\n",
    "            if \"Date\" in df_tmp.columns:\n",
    "                dates = df_tmp[\"Date\"].astype(str)\n",
    "            else:\n",
    "                dates = df_tmp.iloc[:, 0].astype(str)\n",
    "            if not ((\"01-10-2007\" in dates.values) and (\"12-12-2022\" in dates.values)):\n",
    "                not_active_both_dates.append(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read {f}: {e}\")\n",
    "            # Delete unreadable file\n",
    "            try:\n",
    "                os.remove(path)\n",
    "            except Exception as e2:\n",
    "                print(f\"Could not delete {f}: {e2}\")\n",
    "\n",
    "    print(f\"{folder}: {len(not_active_both_dates)} files NOT active in both 01-10-2007 and 12-12-2022\")\n",
    "\n",
    "    # Delete the files not active in both dates\n",
    "    for f in not_active_both_dates:\n",
    "        try:\n",
    "            os.remove(os.path.join(csv_folder, f))\n",
    "        except Exception as e:\n",
    "            print(f\"Could not delete {f}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create the new dataset and stor it in the 'enriched' folder\n",
    "# We use the same date format as the original dataset\n",
    "# We keep data from 02-01-2008 to 12-12-2022\n",
    "\n",
    "input_folder = os.path.join(\"data\", \"cleaned\", \"sp500\", \"csv\")\n",
    "output_folder = os.path.join(\"data\", \"enriched\", \"sp500\", \"csv\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "\n",
    "for f in files:\n",
    "    input_path = os.path.join(input_folder, f)\n",
    "    output_path = os.path.join(output_folder, f)\n",
    "    try:\n",
    "        df = pd.read_csv(input_path, sep=\",\")\n",
    "        stock_symbol = os.path.splitext(f)[0]\n",
    "\n",
    "        # Ensure Date is in datetime format and set as index, then drop the column\n",
    "        if \"Date\" in df.columns:\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d-%m-%Y\", errors=\"coerce\")\n",
    "            date_idx = df.columns.get_loc(\"Date\")\n",
    "            df.insert(date_idx + 1, \"Stock_symbol\", stock_symbol)\n",
    "            df.set_index(pd.DatetimeIndex(df[\"Date\"]), inplace=True)\n",
    "            df.drop(columns=[\"Date\"], inplace=True)\n",
    "        else:\n",
    "            df.insert(1, \"Stock_symbol\", stock_symbol)\n",
    "\n",
    "        # Apply AllStrategy\n",
    "        df.ta.strategy(\n",
    "            ta.AllStrategy,\n",
    "            calculate=True,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        # Filter rows from 02-01-2008 onwards (index is now DatetimeIndex)\n",
    "        \n",
    "        df = df[df.index >= pd.to_datetime(\"02-01-2008\", format=\"%d-%m-%Y\")].copy()\n",
    "\n",
    "        # Set all NaN values to 0\n",
    "        df = df.fillna(0)\n",
    "\n",
    "        # Save to new folder\n",
    "        df.to_csv(output_path)\n",
    "        print(f\"Enriched and saved {f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not process {f}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d426792",
   "metadata": {},
   "source": [
    "### Market Information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030bd63",
   "metadata": {},
   "source": [
    "Here we compute the mean return of the day (ret_1), the rolling means of the mean returns over 5, 10 and 30 days and the rolling mean/std of the mean volume over 5, 10 and 30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6d7037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated market index features saved to data/enriched/market_indexes_aggregated.csv\n"
     ]
    }
   ],
   "source": [
    "def compute_index_features(input_folder, prefix):\n",
    "    files = [f for f in os.listdir(input_folder) if f.endswith(\".csv\")]\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        path = os.path.join(input_folder, f)\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=\",\")\n",
    "            if \"Date\" in df.columns:\n",
    "                df[\"Date\"] = pd.to_datetime(df[\"Date\"], format=\"%d-%m-%Y\", errors=\"coerce\")\n",
    "                df = df.set_index(\"Date\")\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read {f}: {e}\")\n",
    "    all_stocks = pd.concat(dfs)\n",
    "    all_stocks = all_stocks[all_stocks.index.notnull()]\n",
    "    agg = all_stocks.groupby(all_stocks.index).agg({\n",
    "        \"Close\": [\"mean\", \"std\"],\n",
    "        \"Volume\": [\"mean\", \"std\"],\n",
    "    })\n",
    "    agg.columns = ['_'.join(col) for col in agg.columns]\n",
    "    agg = agg.sort_index()\n",
    "    agg[f\"ret_1_{prefix}\"] = agg[f\"Close_mean\"].pct_change()\n",
    "    for w in [5, 10, 30]:\n",
    "        agg[f\"ret_mean_{w}_{prefix}\"] = agg[f\"ret_1_{prefix}\"].rolling(window=w).mean()\n",
    "        agg[f\"ret_std_{w}_{prefix}\"] = agg[f\"ret_1_{prefix}\"].rolling(window=w).std()\n",
    "        agg[f\"volume_mean_{w}_rel_{prefix}\"] = agg[f\"Volume_mean\"].rolling(window=w).mean() / agg[f\"Volume_mean\"]\n",
    "        agg[f\"volume_std_{w}_rel_{prefix}\"] = agg[f\"Volume_mean\"].rolling(window=w).std() / agg[f\"Volume_mean\"]\n",
    "    # Filter rows with date >= 02-01-2008\n",
    "    agg = agg[agg.index >= pd.to_datetime(\"02-01-2008\", format=\"%d-%m-%Y\")]\n",
    "    # Drop unwanted columns\n",
    "    agg = agg.drop(columns=[\"Close_mean\", \"Close_std\", \"Volume_mean\", \"Volume_std\"])\n",
    "    return agg\n",
    "\n",
    "# Compute features for each index\n",
    "folders = {\n",
    "    \"sp500\": \"sp500\",\n",
    "    \"nasdaq\": \"nasdaq\",\n",
    "    \"nyse\": \"nyse\",\n",
    "    \"forbes2000\": \"forbes2000\"\n",
    "}\n",
    "features = []\n",
    "for prefix, folder in folders.items():\n",
    "    input_folder = os.path.join(\"data\", \"cleaned\", folder, \"csv\")\n",
    "    agg = compute_index_features(input_folder, prefix)\n",
    "    features.append(agg)\n",
    "\n",
    "# Merge all features on the date index\n",
    "from functools import reduce\n",
    "df_final = reduce(lambda left, right: pd.merge(left, right, left_index=True, right_index=True, how=\"outer\"), features)\n",
    "df_final = df_final.sort_index()\n",
    "\n",
    "# Save to CSV\n",
    "os.makedirs(\"data/enriched\", exist_ok=True)\n",
    "df_final.to_csv(\"data/enriched/market_indexes_aggregated.csv\")\n",
    "print(\"Aggregated market index features saved to data/enriched/market_indexes_aggregated.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SublimeTextEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
